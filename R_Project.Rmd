---
title: "Projet_commun"
output: pdf_document
date: "2024-11-04"
---

```{css,echo=F}
.badCode {
background-color: #cfdefc; 
}

.corrO { background-color: rgb(255,238,237); }
.corrS { background-color: pink; color: black; border: 1px solid red; }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE,
               cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               class.source="badCode")
```

```{r,warning=F,message=F}
library(ggplot2)
library(gridExtra)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(corrplot)
library(forcats)
library(mclust)
library(cluster)
library(ppclust)
library(ggalluvial)
library(klaR)
library(gridExtra)
library(reshape2)
library(clusterSim)
```

## Partie 1 - Analyse descriptivre du jeu de données

## Statistique descriptive

--- 
Le jeu de données étudié possède 2144 génes et 36 variables qualitatives associées.
Nous allons dans un premier temps afficher ce jeu de données.
---
```{r}
Data = read.table("DataProjet.txt", header =T)
knitr::kable(Data)
```

---
Nous allons ensuite afficher la distribution des mesures d'expression des génes pour les différents traitement, réplicat et temps.
---
```{r}
options(max.print = 1000)
summary(Data)
```

---
On trace ensuite les corrélations entre les différentes variables
---

```{r}
corrplot(cor(Data), method = "ellipse")
```

---
On remarque la répétition d’un même forme entre le réplicat 1 et 2. On remarque également que dans chacune de ces formes la présence de carrés plus foncés pour chaque corrélation des traitements avec eux-même et pour la corrélation entre le traitement 2 et 3. 
Pour étudier plus en détaille ce graphique, on va extraire ces parties et expliquer chacune d'entre elles.
---

---
On va extraire la corrélation pour chaque traitement avec eux même
---

```{r}
corrplot(cor(Data[,1:6]), method = "ellipse")
corrplot(cor(Data[,7:12]), method = "ellipse")
corrplot(cor(Data[,13:18]), method = "ellipse")
```

---
On remarque que les heures ont une influence sur la corrélation. En effet, plus deux heures sont proches, plus la corrélation est élévée, ce qui montre l'évolution temporelle du traitement. Plus le traitement agit longtemps sur le gène, plus le traitement aura un effet important sur le gène.

On va ensuite extraire la corrélation entre chaque traitement.
---

```{r}
corrplot(cor(Data)[1:6,7:12], method = "ellipse")
corrplot(cor(Data)[7:12, 13:18], method = "ellipse")
corrplot(cor(Data)[13:18, 1:6], method = "ellipse")
```

---
On observe que le traitement 2 et 3 sont plutot corrélé, supposant une l'efficacité similaire des deux traitements. Cependant, le traitement est peu corrélé avec le traitement 2 et 3, ce qui suppose encore une efficacité différente entre ces traitements.

On extrait ensuite la corrélation en fonction des réplicats.
---

```{r}
corrplot(cor(Data)[c(19:24), c(1:6)], method = "ellipse")
corrplot(cor(Data)[c(25:30), c(7:12)], method = "ellipse")
corrplot(cor(Data)[c(31:36), c(13:18)], method = "ellipse")
```

---
On peut remarqué une corrélation importante entre les deux réplicat. Ainsi, une expérience produite deux fois renvoit des résultats qui sont corrélés entre eux. Cependant le traitement 2 et 3 pour les 2 réplicat sont plus corrélée à eux même que le traitement 1 ; ce qui suppose que le traitement 2 et 3 a une efficacité plus certaine que le traitement 1. 
Pour le traitement 2 et 3, on remarque que sur la diagonale (même traitement même heure mais réplicat différent), les corrélations sont proche de 1 mais varie légèrement en fonction des heures, cela met l’accent sur les vitesses de réations variantes des traitements selon les gènes. 
---

```{r}
ggplot(melt(Data), aes(x = variable, y = value)) + geom_boxplot() + labs(title = "Boxplot des données", x = "Variable", y = "Valeur (échelle standardisée)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

D’abord, on observe une distinction nette entre les réplicats R1 et R2, témoignant d’une périodicité dans les valeurs d'expression. Ce phénomène s'explique par le fait que les mêmes gènes sont soumis aux mêmes traitements et conditions pour chaque réplicat, bien que des variations aléatoires introduisent de légères différences.

Les boxplots révèlent trois groupes distincts correspondant aux traitements T1, T2, et T3.
- Pour le traitement T1, les médianes sont proches de 0, ce qui suggère une faible réaction des gènes ou l’absence d’un effet global mesurable. Les boîtes étroites et la faible variabilité confirment que la réponse des gènes reste homogène.
- Sous T2, les médianes s’éloignent nettement de 0, indiquant une réaction progressive des gènes au fil du temps.
- Étant une combinaison de T1 et T2, T3 présente des profils similaires à ceux de T2. Cela suggère que l’effet du traitement T2 domine dans l’effet global de T3, induisant une réponse notable des gènes. Cependant, il est possible que l’effet de T1 modère légèrement certaines réponses observées sous T3.

Ces observations s’appliquent de manière presque symétrique aux deux réplicats, illustrant leur homogénéité générale.

## Analyse des variables T_t s_H R_r

---
On translate les données pour pouvoir réaliser l’analyse des variables. 
---

```{r}
# transformation du tableau 
transData = t(Data)
knitr::kable(transData)
```

```{r}
# ACP sur les variables : transposée du tableau
respca<-PCA(transData, scale.unit = T, graph=F)

fviz_pca_ind(respca, 
             #geom = "point", 
             col.ind = "cos2", # Coloration selon la qualité de représentation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,
             title = "Projection des gènes dans l'espace des composantes principales")

fviz_pca_ind(respca, axes = c(1,2), geom = c("text", "point"), col.ind = rep(c(rep("T1", 6), rep("T2", 6), rep("T3", 6)),2), repel = TRUE, title = "ACP des individues regroupés par traitement")
fviz_pca_ind(respca, axes = c(1,2), geom = c("text", "point"), col.ind = rep(c("1h","2h","3h","4h","5h", "6h"), 6), repel = TRUE, title = "ACP des individues regroupés par heure")

fviz_pca_var(respca, 
             col.var = "contrib", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             title = "Projection des variables dans l'espace des composantes principales")

fviz_eig(respca)
```
A partir du graphe des individus on observe :
- Les réplicats (R1 et R2) montrent une cohérence, car ils se regroupent dans l’espace factoriel pour un même traitement et une même heure. Cela confirme que les variations observées dans les données sont principalement dues aux effets des traitements et des temps, et non à des différences techniques entre les réplicats.
- Le traitement 1 se distingue clairement des traitements 2 et 3 en formant un cluster isolé. On peut interprété la première dimension comme la magnitude de la réponse des gènes aux traitements, opposant T1 (réponse quasi nulle) à T2 et T3 (réponses significatives). T2 et T3 sont plus proches l’un de l’autre, confirmant que T3 est dominé par T2.
- La dimension 2 reflète l’évolution temporelle des réponses génétiques, avec une décroissance notable pour T2 et T3 au fil des heures. T1 reste stable sur cet axe, témoignant d'une absence d’effet temporel significatif.

## Clustering :
### Choix du nombre de classes :
On trace l'inertie intraclasse en fonction du nombre de classes possibles et on identifie le nombre optimal de classes en repérant l'apparition du coude. Étant donné le faible nombre d'individus et leur répartition claire sur les axes principaux de l'ACP, on peut raisonnablement anticiper le nombre de classes attendu.

```{r}
# courbe du coude
set.seed(1234)
Kmax<-10
reskmeanscl<-matrix(0,nrow=nrow(transData),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(transData,centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:10,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")
# on peut voir qu'on a entre 3 ou 4 classes, ce qui est attendu vu le graphe de projection des individus de l'ACP
```

```{r}
# Silouhette
Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], dist(transData))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")

aux<-silhouette(reskmeanscl[,2],dist(transData))
fviz_silhouette(aux)+theme(plot.title = element_text(size =9))
rm(df,Silhou,aux)
```

```{r}
reskmeans<-kmeans(transData,centers = 3)
fviz_cluster(reskmeans,transData,ellipse.type = "norm")
fviz_pca_ind(respca,col.ind=as.factor(reskmeans$cluster))
```


```{r}
hward<-hclust(dist(transData),method = "ward.D2")
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(transData,cutree(hward,k)))
}
daux<-data.frame(NbClust=2:Kmax,CH=CH)
ggplot(daux,aes(x=NbClust,y=CH))+geom_line()+geom_point()

ClustCH<-cutree(hward,k=2)
fviz_dend(hward,k=2,show_labels = FALSE,rect = TRUE, rect_fill = TRUE,palette = "npg",rect_border = "npg",
labels_track_height = 0.8)+ggtitle("")
fviz_pca_ind(respca,geom=c("point"),col.ind=as.factor(ClustCH))
```

)
## Analyse des individus Gènes
# Partie ACP des individus
```{r}
# Exécution de l'ACP sur les individus (les gènes)
pca_result_ind <- PCA(Data, scale.unit = FALSE, graph = FALSE)  # ACP sans mise à l'échelle

# Visualisation des individus (gènes) en fonction du cos2 pour évaluer la qualité de leur projection
fviz_pca_ind(pca_result_ind, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

# Afficher les valeurs cos2 des individus pour analyser leur qualité de représentation
pca_result_ind$var$cos2

# Visualisation de l'inertie des axes principaux pour observer la variance expliquée
fviz_eig(pca_result_ind)
```

---
Le premier aspect qui se démarque est la formation de deux clusters distincts. Cela suggère que les gènes se regroupent en fonction de leur expression similaire sous les différentes conditions. Les points proches les uns des autres représentent des gènes ayant des profils d'expression similaires, tandis que les points éloignés indiquent des gènes présentant des différences notables dans leur expression. La coloration des points en fonction du cos2 permet de visualiser la qualité de la projection des gènes dans cet espace réduit, avec des couleurs chaudes signalant une meilleure représentation et une contribution plus forte à l'explication de la variance dans l'espace de faible dimension.
---

# Clustering sur les individus : K-means

```{r}
# Évolution de l'inertie intraclasse pour choisir le nombre optimal de clusters
Kmax <- 15
reskmeanscl <- matrix(0, nrow = nrow(Data), ncol = Kmax - 1)
Iintra <- NULL

# Calcul de l'inertie pour chaque nombre de clusters
for (k in 1:Kmax) {
  resaux <- kmeans(Data, k, nstart = 1)
  reskmeanscl[, k - 1] <- resaux$cluster
  Iintra <- c(Iintra, resaux$tot.withinss)
}

# Affichage de l’évolution de l’inertie en fonction du nombre de clusters
df <- data.frame(K = 1:15, Iintra = Iintra)
ggplot(df, aes(x = K, y = Iintra)) +
  geom_line() +
  geom_point() +
  xlab("Nombre de clusters") +
  ylab("Inertie intraclasse")

```
---
L'inertie intra-classe diminue à mesure que le nombre de clusters augmente. Cependant, lorsque le nombre de clusters atteint une certaine valeur, l'inertie devient stable et ne diminue plus de manière significative. Le point de coude dans le graphique nous aide à identifier le nombre optimal de clusters. Dans ce cas, le coude se forme lorsque le nombre de clusters est égal à 2, ce qui suggère que 2 clusters représentent le meilleur compromis entre la compacité des groupes et la simplicité du modèle.
---

```{r}
# Le critère silhouette
Silhou <- NULL
for (k in 2:Kmax) {
  aux <- silhouette(kmeans(Data, k)$cluster, daisy(Data))
  Silhou <- c(Silhou, mean(aux[, 3]))
}

# Affichage du critère silhouette pour chaque nombre de clusters
df <- data.frame(K = 2:Kmax, Silhouette = Silhou)
ggplot(df, aes(x = K, y = Silhouette)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "bottom")

# Identifier le nombre optimal de clusters basé sur la silhouette
which.max(Silhou)

# Visualisation de la silhouette pour le nombre optimal de clusters
aux <- silhouette(kmeans(Data, centers = which.max(Silhou) + 1)$cluster, daisy(Data))
fviz_silhouette(aux) + theme(plot.title = element_text(size = 9))

```
---
Le critère silhouette évalue la qualité du clustering. La silhouette est élevée, ce qui signifie que les points sont bien regroupés et éloignés des autres groupes. L’analyse permet de confirmer que le nombre optimal de clusters est 2.
---
```{r,eval=F}
reskmeans<-kmeans(Data, 2)  
reskmeans$cluster
fviz_cluster(reskmeans, data=Data,ellipse=F,geom=c("point"))
```

```{r,eval=F}
fviz_pca_ind(pca_result_ind, col.ind=as.factor(reskmeans$cluster), geom="point")
```


# Clustering sur les individus : DBSCAN
```{r,eval=F}
# Grid de recherche pour le paramètre eps et minPts
minPts <- seq(5, 15, 1)
eps <- seq(0.5, 10, 0.3)
NBCluster <- matrix(0, nrow = length(minPts), ncol = length(eps))
NBNonCl <- matrix(0, nrow = length(minPts), ncol = length(eps))

# Recherche de l'optimal eps et minPts
for (i in 1:length(minPts)) {
  for (j in 1:length(eps)) {
    res <- dbscan::dbscan(Data, eps = eps[j], minPts = minPts[i])
    NBCluster[i, j] <- length(table(res$cluster)) - 1
    NBNonCl[i, j] <- sum(res$cluster == 0)
  }
}

# Visualisation des résultats DBSCAN
df <- data.frame(eps = rep(eps, each = length(minPts)),
                 minPts = as.factor(rep(minPts, length(eps))),
                 NBCluster = c(NBCluster),
                 NBNonCl = c(NBNonCl) * 100 / nrow(Data))

# Affichage des clusters formés en fonction de eps et minPts
ggplot(df, aes(x = eps, y = NBCluster, col = minPts)) + 
  geom_point() + 
  geom_line()

# Affichage des points non-clustérisés (bruit)
ggplot(df, aes(x = eps, y = NBNonCl, col = minPts)) + 
  geom_point() + 
  geom_line()

```
---
Les courbes obtenues pour l'analyse DBSCAN montrent l'impact des paramètres eps (distance maximale) et minPts (nombre minimum de voisins) sur la formation des clusters et l'identification du bruit. Les courbes montrent que l'augmentation de eps réduit le nombre de clusters et de points de bruit, tandis que l'augmentation de minPts rend la formation des clusters plus stricte, réduisant aussi les clusters détectés. Les graphiques aident à ajuster ces paramètres pour optimiser le nombre de clusters et limiter le bruit.
---

```{r,eval=F}
# A COMPLETER
# k représente le nombre de variables dans les données
k <- ncol(Data)
k

# Calcul des distances aux k plus proches voisins
dbscan::kNNdistplot(Data, k)
abline(h = 8.5)  # Ligne horizontale pour identifier l'eps optimal (coude)

```
---
Le "coude" de la courbe nous indique un bon choix pour le paramètre eps (ici, eps = 8.5). Cette méthode consiste à calculer la moyenne des distances des k plus proches voisins pour chaque point. Ensuite, nous ordonnons ces distances de manière croissante pour identifier le point d'inflexion (le "coude") qui détermine le meilleur epsilon pour DBSCAN.
---
```{r,eval=F}
# A COMPLETER
res.db = dbscan::dbscan(Data, minPts = 8, eps = 8.5)
res.db
fviz_cluster(res.db, Data, geom="point",ellipse="FALSE")+
  theme(legend.position="none")+
  xlab("")+ylab("")+ggtitle("Avec DBSCAN")

table(res.db$cluster)
```
---
Les clusters obtenus avec l'algorithme DBSCAN sont globalement similaires à ceux générés par K-means, à l'exception de 13 gènes qui ne sont pas classifiés par DBSCAN. Ces gènes sont probablement considérés comme du bruit ou isolés, car DBSCAN ne les associe à aucun cluster en raison de leur éloignement ou de la densité insuffisante des voisins à proximité.
---
```{r,eval=F}
fviz_pca_ind(pca_result_ind, col.ind=as.factor(res.db$cluster), geom="point")
```

```{r}
# Comparaison des résultats de K-means et DBSCAN
clust1 <- paste("K-k", reskmeans$cluster, sep = "")
clust2 <- paste("Dbscan-k", res.db$cluster, sep = "")
table(clust1, clust2)

# Visualisation sous forme de diagramme d’alluvion pour la comparaison des clusters
Tab <- melt(table(clust1, clust2))
ggplot(Tab, aes(y = value, axis1 = clust1, axis2 = clust2)) +
  geom_alluvium(aes(fill = clust1)) +
  geom_stratum(width = 1 / 12) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme(legend.position = "none")

```

---
Les courbes obtenues comparent les résultats des algorithmes K-means et DBSCAN. Le tableau de comparaison montre les correspondances et divergences entre les clusters identifiés par les deux méthodes. Le diagramme visualise ces relations : des flux larges entre les clusters indiquent une forte correspondance, tandis que des petits flux correspondent à des divergences, comme des points considérés comme bruit par DBSCAN mais regroupés par K-means. 
---

# Clustering Hiérarchique (HAC)

```{r}
# Couper l'arbre à un certain nombre de clusters
k <- 2  # Par exemple, couper l'arbre pour obtenir 2 clusters
clusters <- cutree(hclust_res, k)

# Visualisation du dendrogramme avec les couleurs des clusters
plot(hclust_res, main = "Dendrogramme avec 2 clusters")
rect.hclust(hclust_res, k = k, border = "red")  # Ajouter des boîtes rouges autour des clusters

```
---
Le dendrogramme montre que les groupes qui se fusionnent tôt sont très similaires, tandis que ceux qui se rejoignent plus tard présentent des différences plus marquées. On observe que le nombre optimal de clusters, égal à 2, est cohérent avec les résultats obtenus par DBSCAN et K-means. Cela suggère que les trois méthodes identifient une structure similaire dans les données, avec une séparation nette entre deux groupes principaux.
---

```{r}
library(pheatmap)

# Créer une heatmap avec dendrogramme
pheatmap(Data[1:20, ], cluster_rows = TRUE, cluster_cols = TRUE, main = "Heatmap avec Dendrogramme sur les 20 premiers gènes")
```

---
La heatmap des 20 premiers gènes montre l'expression des gènes à travers différentes conditions, accompagnée de dendrogrammes qui regroupent les gènes et les conditions selon leurs profils d'expression. On remarque que les gènes du cluster en haut à droite, sont fortement corrélés avec les traitements 2 et 3. On peut en déduire que l'un des clusters regroupe principalement les gènes ayant subi les traitements 2 et 3, tandis que l'autre cluster correspond majoritairement aux gènes ayant subi le traitement 1.
---

## Etude des différences entre les deux réplicats

Nous cherchons à étudier la différence entre les deux réplicats. Pour ce faire, nous définissons une nouvelle variable \( Y_{tsg} \) :
\[
Y_{tsg} = Y_{tsgR1} - Y_{tsgR2}
\]
L'objectif est de modéliser cette variable \( Y_{tsg} \) en fonction de deux facteurs principaux :
\begin{itemize}
  \item \textbf{Le temps} (\( Temps \)), qui est une variable quantitative.
  \item \textbf{Le traitement} (\( Traitement \)), qui est une variable qualitative.
\end{itemize}
Pour ce faire, nous utilisons un \textbf{modèle ANCOVA avec interaction}, qui permet de modéliser la relation entre la variable dépendante \( Y_{tsg} \) et les deux facteurs (temps et traitement), ainsi que leur interaction.
\[
Y_{tsg} = \beta_0 + \beta_1 \cdot Temps + \beta_2 \cdot Traitement + \beta_3 \cdot (Temps \times Traitement) + \epsilon
\]

---
Les lois de probabilité associés aux valeurs observées pour les deux réplicats sont elles significativement différentes ? Même question en se concentrant sur chaque traitement pris séparément. --> Réponses à partir du cours de janvier
---

---
Consigne : Etudier l'effet combiné du temps et du traitement sur la différence des réplicats à l'aide d'un modèle linéaire
---

```{r}
# Etape 1 : On effectue la différence des réplicats
p = ncol(Data)
#ncol(Data[,1:(p/2)])
#ncol(Data[,(p/2 + 1):p])
Data_Diff_R = Data[,1:(p/2)] - Data[,((p/2) + 1):p]
colnames(Data_Diff_R) <- sub("_[^_]*$", "", colnames(Data[,1:(p/2)]))
knitr::kable(Data_Diff_R)
```

```{r}
#Etape 2 : Création de Yij de telle sorte que Y_ij = Y_tsg (l'ordre est traitement, temps et gènes)
Y = as.vector(as.matrix(Data_Diff_R))
```

```{r}
#Etape 3 : Création des noms de lignes du vecteur Y
noms_Y <- outer(colnames(Data_Diff_R), rownames(Data_Diff_R), paste, sep="_")
noms_Y <- as.vector(t(noms_Y))

# Vérification des dimensions
length(noms_Y)
length(Y)

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)
temps <- as.numeric(sapply(strsplit(noms_Y, "[_h]"), function(x) x[2]))

# Etape 5 : Création du tableau pour le modèle linéaire
matrix = as.data.frame(cbind(Y, traitement, temps))
matrix$temps <- as.numeric(matrix$temps)
matrix$Y <- as.numeric(matrix$Y)
```

```{r}
rownames(matrix) <- noms_Y
knitr::kable(matrix)
```

```{r}
# Modèle ANCOVA à 2 facteur avec intéraction
ML <- lm(matrix$Y~matrix$traitement*matrix$temps, data = matrix)
summary(ML)
boxplot(matrix$Y~matrix$traitement*matrix$temps, data =matrix)
```

```{r}
# Modèle ANCOVA à 2 facteur sans intéractions
ML_sans_interaction = lm(matrix$Y~matrix$traitement+matrix$temps, data = matrix)
summary(ML_sans_interaction)
boxplot(matrix$Y~matrix$traitement+matrix$temps, data =matrix)
```

```{r}
# Courbes d'interactions
library(ggplot2)
library(gridExtra)

# Modèle sans interaction
M_non_interaction <- lm(Y ~ traitement + temps, data = matrix)

# Modèle avec interaction
M_interaction <- lm(Y ~ traitement * temps, data = matrix)

# Création des nouvelles données pour prédiction
new_data <- expand.grid(
  traitement = unique(matrix$traitement),
  temps = seq(min(matrix$temps), max(matrix$temps), length.out = 100)
)

# Prédictions
new_data$Y_non_interaction <- predict(M_non_interaction, newdata = new_data)
new_data$Y_interaction <- predict(M_interaction, newdata = new_data)

# Graphique pour le modèle sans interaction
plot_non_interaction <- ggplot(new_data, aes(x = temps, y = Y_non_interaction, color = traitement)) +
  geom_line(size = 1) +
  labs(title = "Modèle sans interaction",
       x = "Temps",
       y = "Valeurs prédites de Y",
       color = "Traitement") +
  theme_minimal()

# Graphique pour le modèle avec interaction
plot_interaction <- ggplot(new_data, aes(x = temps, y = Y_interaction, color = traitement)) +
  geom_line(size = 1) +
  labs(title = "Modèle avec interaction",
       x = "Temps",
       y = "Valeurs prédites de Y",
       color = "Traitement") +
  theme_minimal()

# Affichage côte à côte
grid.arrange(plot_non_interaction, plot_interaction, ncol = 2)
```
Dans le modèle sans interaction, les courbes sont parallèles, reflétant l'absence d'interdépendance entre le traitement et le temps. En revanche, dans le modèle avec interaction, les courbes montrent des variations de pente ou des croisements, indiquant une interaction significative entre ces deux variables. À partir de ces deux représentations, un test de sous-modèle est effectué pour déterminer si l'interaction doit être conservée dans le modèle final.

---
On commence à tester l'hypothèse de non-intéraction entre le facteur traitement et le variable temps.
---

```{r}
# Comparaison du modèle ANCOVA avec intéractions et sans intéractions
anova(ML, ML_sans_interaction)
```

---
La p-valeur observée est inférieur à 5% (1.426e-15 < 0.05). On rejette donc l'hypothèse de nullité des intéractions.
On conclut donc la présence d'intéraction dans le modèle; tester l'absence de facteur traitement et de variable temps n'a donc pas d'intéret, car toute variable constituant une interaction doit apparaître dans le modèle.
---


---
Consigne : Peut-on prévoir l’expression des gènes à 6h à partir de celle observée à 1h et du traitement
considéré ? Commenter la qualité de l’ajustement et la visualiser graphiquement.
---

```{r}
# extraire les Y à 1h et créer une matrice
p = ncol(Data)
Data_moy_R = (Data[,1:(p/2)] + Data[,((p/2) + 1):p])/2
Data_moy_R_1h = Data_moy_R[,c(1,7,13)]
Data_moy_R_6h = Data_moy_R[,c(6,12,18)]

colnames(Data_moy_R_1h) <- sub("_[^_]*$", "", colnames(Data_moy_R_1h))
#knitr::kable(Data_moy_R_1h)

colnames(Data_moy_R_6h) <- sub("_[^_]*$", "", colnames(Data_moy_R_6h))
#knitr::kable(Data_moy_R_6h)

Y_moy_1h = as.vector(as.matrix(Data_moy_R_1h))
Y_moy_6h = as.vector(as.matrix(Data_moy_R_6h))

#Etape 3 : Création des noms de lignes du vecteur Y
noms_Y <- outer(colnames(Data_moy_R_1h), rownames(Data_moy_R_1h), paste, sep="_")
noms_Y <- as.vector(t(noms_Y))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)

# Etape 5 : Création du tableau pour le modèle linéaire
matrixMoy = as.data.frame(cbind(Y_moy_6h, Y_moy_1h, traitement))
matrixMoy$Y_moy_1h <- as.numeric(matrixMoy$Y_moy_1h)
matrixMoy$Y_moy_6h <- as.numeric(matrixMoy$Y_moy_6h)

knitr::kable(matrixMoy)
```


```{r}
# Prédictions à partir du modèle
matrixMoy$Predicted <- predict(M_1h_to_6h, newdata = matrixMoy)

# Tracé des valeurs observées (Y_moy_6h) par rapport aux valeurs prédites
ggplot(matrixMoy, aes(x = Predicted, y = Y_moy_6h)) +
  geom_point(aes(color = traitement), alpha = 0.6) +  # Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
```
On observe que les valeurs prédites sont principalement proches de 0, tandis que les valeurs observées, en particulier pour les traitements T2 et T3, diffèrent significativement de 0. Cela suggère que l'expression des gènes à 1h ne constitue pas un bon indicateur pour prédire celle à 6h.
En effet, 1 heure représente un stade relativement précoce, et les gènes n'ont probablement pas eu suffisamment de temps pour réagir aux traitements. Par conséquent, il est difficile de faire des prédictions fiables sur l'expression génique à 6 heures en se basant sur des données obtenues à 1 heure.

```{r}
M_1h_to_6h <- lm(Y_moy_6h~Y_moy_1h*traitement, data = matrixMoy)
summary(M_1h_to_6h)
# tracer les courbes des valeurs predites vs les valeurs observées
# calculer les theta chapeau pour voir la difference (courbe residuals)
```


```{r}
#par(mfrow = c(2, 2))
plot(M_1h_to_6h)
```


```{r}
M_1h_to_6h_no_inter <- lm(Y_moy_6h ~ Y_moy_1h + traitement, data = matrixMoy)
anova(M_1h_to_6h_no_inter, M_1h_to_6h)
```
le test indique que l’ajout de l’interaction améliore significativement le modèle (p-valeur < 0.05), cela suggère que :
- L’effet de Y_1h sur Y_6h varie selon les traitements.
- L’interaction entre Y_1h et le traitement est pertinente.

### Conclusion
Le modèle ajusté montre une qualité d'ajustement modérée, avec un R2R2 de 27.06%, indiquant que 27% de la variance de Y6hY6h​ est expliquée par Y1hY1h​ et le traitement. Les termes d’interaction entre Y1hY1h​ et le traitement sont hautement significatifs (p<2e−16p<2e−16), ce qui montre que l’effet de Y1hY1h​ sur Y6hY6h​ varie selon le traitement. Les graphiques des résidus confirment que les hypothèses de linéarité et de normalité sont globalement respectées, bien que le modèle laisse une part importante de la variance inexpliquée. Cela suggère que Y1hY1h​ et les traitements contribuent à l’évolution temporelle de Y6hY6h​, mais d’autres facteurs pourraient être impliqués.

---
Consigne : Reprendre la question précédente en remplaçant 1h par 3h et comparer les résultats obtenus dans
les deux cas.
---
```{r}
p = ncol(Data)

Data_moy_R_3h = Data_moy_R[,c(3,9,15)]

colnames(Data_moy_R_3h) <- sub("_[^_]*$", "", colnames(Data_moy_R_3h))
#knitr::kable(Data_moy_R_3h)

Y_moy_3h = as.vector(as.matrix(Data_moy_R_3h))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)

# Etape 5 : Création du tableau pour le modèle linéaire
matrixMoy2 = as.data.frame(cbind(Y_moy_6h, Y_moy_3h, traitement))
matrixMoy2$Y_moy_6h <- as.numeric(matrixMoy2$Y_moy_6h)
matrixMoy2$Y_moy_3h <- as.numeric(matrixMoy2$Y_moy_3h)

knitr::kable(matrixMoy2)
```


```{r}
# Prédictions à partir du modèle
matrixMoy2$Predicted <- predict(M_3h_to_6h, newdata = matrixMoy2)

# Tracé des valeurs observées (Y_moy_6h) par rapport aux valeurs prédites
library(ggplot2)
ggplot(matrixMoy2, aes(x = Predicted, y = Y_moy_6h)) +
  geom_point(aes(color = traitement), alpha = 0.6) +  # Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
```
Modèle 3h :
- Residual Standard Error (RSE) : 1.168
- R² ajusté : 0.770
- La variance expliquée est beaucoup plus élevée, indiquant que les prédictions du modèle pour les données à 3h sont nettement meilleures.

Interprétation :
Le modèle basé sur les données de 3h est nettement plus performant que celui de 1h, avec un R² ajusté presque trois fois supérieur et un RSE significativement plus faible. Cela signifie que les valeurs à 3h expliquent beaucoup mieux les valeurs à 6h.
On peut voir aussi que les valeurs predites correspondent aux valeurs observés. On a donc une meilleure prédiction comparé au modele precedent

```{r}
M_3h_to_6h <- lm(Y_moy_6h~Y_moy_3h*traitement, data = matrixMoy2)
summary(M_3h_to_6h)
```


```{r}
par(mfrow = c(2, 2))
plot(M_3h_to_6h)
```


```{r}
M_3h_to_6h_no_inter <- lm(Y_moy_6h ~ Y_moy_3h + traitement, data = matrixMoy2)
anova(M_3h_to_6h_no_inter, M_3h_to_6h)
```



## Etude de l’expression des gènes pour le traitement T3 à 6h :
---
Consigne : Quelles sont les variables prédictives pour le traitement T3 à 6h parmi les différents temps observés
pour les traitements T1 et T2 ?
---

```{r}
# Matrice moyenne des replicats
p = ncol(Data)
Moy_Rep = (Data[,1:(p/2)] + Data[,((p/2) + 1):p])/2
colnames(Moy_Rep) <- sub("_[^_]*$", "", colnames(Data[,1:(p/2)]))
#knitr::kable(Moy_Rep)

modele_T3_all <- lm(T3_6h ~ T1_1h + T1_2h + T1_3h + T1_4h + T1_5h + T1_6h +
                      T2_1h + T2_2h + T2_3h + T2_4h + T2_5h + T2_6h, 
                    data = Moy_Rep)
summary(modele_T3_all)

mod.AIC = stepAIC(modele_T3_all,direction="backward")
# vif(modele_T3_all) # Calculer les facteurs d'inflation de la variance
```


```{r}
library(reshape2)
library(ggplot2)
cor_matrix <- cor(Moy_Rep[, c("T3_6h", "T1_1h", "T1_2h", "T1_3h", "T1_4h", 
                           "T1_5h", "T1_6h", "T2_1h", "T2_2h", "T2_3h", 
                           "T2_4h", "T2_5h", "T2_6h")])

# Convertir en format long
cor_long <- melt(cor_matrix)

# Créer une heatmap
ggplot(cor_long, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  theme_minimal() +
  labs(title = "Corrélation entre Y_T3_6h et les autres variables", 
       x = "Variables", y = "Variables")

# Extraire les coefficients significatifs
coef_model <- summary(modele_T3_all)$coefficients
coef_df <- data.frame(
  Variable = rownames(coef_model),
  Coefficient = coef_model[, "Estimate"],
  P_value = coef_model[, "Pr(>|t|)"]
)

# Filtrer les variables significatives (p-value < 0.05)
coef_df <- coef_df[coef_df$P_value < 0.05, ]

# Créer un barplot des coefficients
ggplot(coef_df, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Coefficients significatifs du modèle", x = "Variable", y = "Coefficient")

new_modele_T3_all <- lm(T3_6h ~ T1_1h + T1_2h + T1_3h + T1_4h + T1_6h +
                      T2_2h + T2_3h + T2_4h + T2_5h + T2_6h, 
                    data = Moy_Rep)
anova(new_modele_T3_all,modele_T3_all)
```

```{r}
tmp = Moy_Rep
tmp$Predicted <- predict(new_modele_T3_all, newdata = tmp)
ggplot(tmp, aes(x = Predicted, y = T3_6h)) +
  geom_point() +# Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
```

---
Consigne : Peut-on prédire les gènes sur-exprimés (codés 1) et les gènes sous-exprimés (codés 0) à 6h pour le
traitement T3 à partir des observations pour les traitements T1 et T2 et les heures 1 à 3 pour ces
mêmes gènes ?
---

```{r}
# Filtrer les données en excluant les valeurs intermédiaires (-1 <= T3_6h <= 1)
x = Moy_Rep[Moy_Rep$T3_6h < 1 & Moy_Rep$T3_6h > -1, ]
# 8 genes non classés
filtered_data <- Moy_Rep[Moy_Rep$T3_6h < -1 | Moy_Rep$T3_6h > 1, ]
# Définir la colonne target selon les critères donnés
filtered_data$target <- as.factor(ifelse(filtered_data$T3_6h > 1, 1, 0))
filtered_data <- filtered_data[, c("T1_1h", "T1_2h", "T1_3h", "T2_1h", "T2_2h", "T2_3h","target")]
table(filtered_data$target)

model <- glm(filtered_data$target ~. , data = filtered_data, family = "binomial")

summary(model)

step.backward = step(model, direction="backward",k=log(nrow(filtered_data)))

bestmodel = glm(filtered_data$target ~T2_2h + T1_2h +T1_3h + T2_3h , data = filtered_data, family = "binomial")
anova(model,bestmodel)
```


```{r}
# Prédire sur les données de test ou validation
predictions <- predict(model, newdata = filtered_data, type = "response")

# Convertir les prédictions en classes (0 ou 1) en fonction d'un seuil de 0.5
predicted_class <- ifelse(predictions > 0.5, 1, 0)

# Matrice de confusion
table(predicted_class, filtered_data$target)
adjustedRandIndex(predicted_class, filtered_data$target)

roc_curve <- roc(filtered_data$target, predictions)
plot(roc_curve, main = "Courbe ROC", col = "blue", lwd = 2)
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
```
