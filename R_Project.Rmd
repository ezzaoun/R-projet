---
title: "Projet d'étude"
author: "Castello Emeline, Seye Papa Samba et Aoun Ezzeddine"
institute : "INSA Toulouse"
date: "`r Sys.Date()`"
#bibliography: ""
output:
  pdf_document :
    latex_engine: xelatex
    toc : TRUE
    keep_tex: true
    toc_depth : 2
    number_section : TRUE
    fig_caption: yes
    pandoc_args: ["--standalone", "--number-sections"]
encoding: UTF-8
header-includes:
   - \usepackage[utf8]{inputenc}
   - \usepackage{dsfont}
   - \usepackage{float}
   - \usepackage{color}
   - \newcommand{\1}{\mathds{1}}
editor_options:
  markdown:
    wrap: 72
geometry: margin=1in
fontsize: 10pt
---

```{css,echo=F}
.badCode {
background-color: #cfdefc; 
}

.corrO { background-color: rgb(255,238,237); }
.corrS { background-color: pink; color: black; border: 1px solid red; }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE,
               cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               class.source="badCode")
```

```{r packages,warning=F,message=F,echo=F}
library(ggplot2)
library(gridExtra)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(corrplot)
library(forcats)
library(mclust)
library(cluster)
library(ppclust)
library(ggalluvial)
library(klaR)
library(gridExtra)
library(reshape2)
library(clusterSim)
library(pROC)
library(tidyverse)
library(leaps)
library(float)
```
# Introduction

Ce projet vise à analyser les données d’expression de 2144 gènes d’une plante modèle, mesurées sous trois traitements ($T1$, $T2$, $T3$), six temps ($1h$ à $6h$), et deux réplicats biologiques ($R1$ et $R2$).

L’objectif est de répondre à plusieurs problématiques clés : explorer la structure des données, étudier les effets des traitements et du temps, prédire l’expression des gènes à différents temps, et identifier les facteurs influençant l’expression. Ces analyses reposent sur des méthodes d'exploration de données, de clustering, et de modélisation statistique, implémentées en R.

Ce rapport présente notre démarche, les résultats obtenus et leur interprétation biologique, tout en mettant en avant la pertinence des outils statistiques utilisés.

# Analyse descriptive du jeu de données

```{r Data, eval =T, echo = F}
Data = read.table("DataProjet.txt", header =T)
```

Nous commençons par étudier les corrélations entre les différentes variables.

```{r Corrplot, eval = T, echo = F, fig.width=4, fig.height=3, fig.align = "center", ,fig.cap="\\label{fig:Correlation}Corrélation entre les différentes variables",fig.pos='H'}
corrplot(cor(Data), method = "ellipse", tl.cex = 0.6)
```

La Figure \ref{fig:Correlation} met en évidence la répétition d’un même motif entre les réplicats 1 et 2. On observe une structure en blocs dans la matrice de corrélation. Le bloc situé en haut à gauche met en évidence de fortes corrélations du traitement 1 avec lui-même. De même, les traitements 2 et 3 présentent de fortes corrélations internes, mais aussi entre eux, formant un second bloc distinct.
Pour une analyse plus détaillée, nous extrairons ces éléments et les examinerons individuellement. Dans un premier temps, nous représenterons la corrélation propre à chaque traitement.

```{r Corrplot_intratraitement, eval = T, echo = F,fig.width=2, fig.height=2, fig.show='hold', fig.align = "center", results = "asis", fig.cap ="\\label{fig:Correlationintra}corrélation propre à chaque traitement",fig.pos='H'}
#par(mar = c(5,2,2,2))
corrplot(cor(Data[,1:6]), method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data[,7:12]), method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data[,13:18]), method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
```

La figure \ref{fig:Correlationintra} met en évidence l’influence du temps sur la corrélation. Plus deux mesures sont prises à des moments rapprochés, plus leur corrélation est élevée, illustrant ainsi l’évolution progressive de l’effet du traitement. Plus le traitement est appliqué longtemps, plus son impact sur l’expression du gène devient marqué. Nous allons ensuite extraire et analyser la corrélation entre chaque traitement.

```{r Correlation_entre_traitement,eval = T, echo = F,fig.width=2, fig.height=2,fig.show='hold', fig.align = "center", fig.cap = "\\label{fig:Correlation_inter}Corrélation entre les traitements",fig.pos='H'}
corrplot(cor(Data)[1:6,7:12], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[7:12, 13:18], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[13:18, 1:6], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
```

La Figure \ref{fig:Correlation_inter} montre une corrélation marquée entre les traitements 2 et 3, suggérant une expression similaire. En revanche, le traitement 1 présente une faible corrélation avec les traitements 2 et 3, indiquant une différence d’expression. 

```{r Correlation_replicat, eval = F, echo = F,fig.width=2, fig.height = 2, fig.show='hold', fig.align = "center", fig.cap = "\\label{fig:CorrelationRep}Corrélation en fonction des réplicats",fig.pos='H'}
#Nous extrayons également la corrélation en fonction des réplicats pour approfondir cette analyse.
corrplot(cor(Data)[c(19:24), c(1:6)], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[c(25:30), c(7:12)], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[c(31:36), c(13:18)], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
#D'après la Figure \ref{fig:CorrelationRep}, on observe une forte corrélation entre les deux réplicats, ce qui suggère que le facteur #réplicat n’a pas d’influence significative sur l’expression des gènes. Toutefois, les traitements 2 et 3 présentent une corrélation #plus élevée entre leurs réplicats que le traitement 1, indiquant une expression plus stable pour ces deux traitements.
```



Nous  traçons un viloin plot pour visualiser la distribution des données.

```{r Violin_plot, eval = T, echo = F,fig.height=3, fig.align = "center", fig.cap = "\\label{fig:violin}Distribution des Expressions par Réplicat, Temps et Traitement",fig.pos='H'}
# violin plot pour mieux visualiser 
data_long <- melt(Data, 
                  variable.name = "Condition", 
                  value.name = "Expression")

# Ajouter des colonnes pour séparer Réplicats, Traitements et Temps
data_long$Replicate <- ifelse(grepl("R1", data_long$Condition), "R1", "R2")
data_long$Treatment <- sub("_.*", "", data_long$Condition)
data_long$Time <- gsub(".*_(\\d+h)_.*", "\\1", data_long$Condition)

# Tracer le violin plot avec ggplot
ggplot(data_long, aes(x = Time, y = Expression, fill = Treatment)) +
  geom_violin(scale = "width", trim = TRUE) +
  facet_wrap(~ Replicate) +  # Facet par réplicat
  labs(
       x = "Temps",
       y = "Expression",
       fill = "Traitement") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
        axis.text = element_text(size = 5))
```

Sur la Figure \ref{fig:violin}, une distinction claire entre les réplicats R1 et R2 est visible, suggérant une certaine périodicité dans les valeurs d'expression.

On cosntate trois groupes distincts, correspondant aux traitements T1, T2 et T3 :

- $T1$ présente des valeurs d'expression globalement proches de 0, suggérant une faible expression des gènes.

- $T2$ montre une distribution plus décalée, indiquant une réponse progressive des gènes au fil du temps.

- $T3$, combinaison de T1 et T2, affiche des profils similaires à T2, ce qui suggère que l'effet de T2 domine dans l’expression des gènes sous T3, bien que l’influence de T1 puisse moduler certaines réponses.

Ces tendances sont cohérentes entre les deux réplicats, témoignant de leur homogénéité globale.


# Analyse des variables T\_t s\_H R\_r

## Analyse des composantes principales

Pour effectuer des analyses sur les variables, nous transposons notre jeu de données afin de considérer les variables initiales comme de nouveaux individus. Cette approche permet d'explorer les relations entre les variables et de visualiser leur structure dans un espace réduit. 

Une Analyse en Composantes Principales (ACP) sera réalisée sur ce jeu de données transposé. L’objectif est d’identifier les vecteurs qui maximisent l’inertie de la projection des données sur ces vecteurs. Ces derniers correspondent aux vecteurs propres associés aux plus grandes valeurs propres de la matrice de covariance des données, représentant ainsi les axes principaux de l’ACP.

Dans notre cas, il n'est pas nécessaire de réduire les données, car toutes les variables sont exprimées sur la même échelle.

```{r ACP_variables,echo=F, fig.height=3,fig.align='center',fig.cap="\\label{fig:AcpVar}Projection des individus",fig.pos='H'}
# Transposition des données
transData <- t(Data)

# ACP sur les variables : transposée du tableau
respca <- PCA(transData, scale.unit = FALSE, graph = FALSE)

# Projection des individus dans l'espace des composantes principales
fviz_pca_ind(
  respca,
  axes = c(1, 2),
  geom = c("text", "point"),
  col.ind = rep(c(rep("T1", 6), rep("T2", 6), rep("T3", 6)), 2),
  repel = TRUE,
  labelsize = 2, # Réduction de la taille des étiquettes
  pointsize = 1  # Réduction de la taille des points
)
```

D'après la figure \ref{fig:AcpVar}, on observe :

- Les réplicats (R1 et R2) montrent une cohérence, car ils se regroupent dans l’espace factoriel pour un même traitement et une même heure. Cela confirme que les variations observées dans les données sont principalement dues aux effets des traitements et des temps, et non à des différences techniques entre les réplicats.

- Le traitement 1 se distingue des traitements 2 et 3 en formant un cluster isolé. L'axe 1 est tiré d'un coté par T1 à toutes les heures et dans les deux réplicats, et de l'autre coté par T2 et T3, surtout après 4h. On observe également des petits groupes isolés en haut, correspondants aux premières heures (1h, 2h, 3h) des traitements T2 et T3. Cela peut être interprété comme le passage d'un état où les gènes réagissent faiblement (à droite) à un état où ils commencent à répondre plus fortement au traitement. On peut interpéter Cette dimension comme le niveau d’expression des gènes.

- La dimension 2 semble être liée à la temporalité, avec une décroissance des heures du haut vers le bas.

## Clustering 

### K-means
Pour cet algorithme, on cherche à minimiser l'\texttt{inertie intraclasse}, qui est définie par : 
$$
I_{\text{inter}} = \sum_{k=1}^K |C_k| \times d(m_k, c)^2 \quad \text{où} \quad m_k = \frac{1}{|C_k|} \sum_{i \in C_k} x_i \text{ est le centre de gravité de la classe } C_k.
$$
Pour faire cette étude, nous devons avant tout déterminer le nombre de clusters \( K \). Pour cela, nous optons pour le choix du critère \texttt{silhouette} permettant d'évaluer la qualité du clustering en mesurant la cohésion intra-classe et la séparation entre les classes. Le nombre optimal de clusters \( \hat{K} \) est celui qui maximise \( S(K) \). Nous traçons aussi l'inertie intraclasse.

```{r nb_classes, echo=F, fig.height=3,fig.align='center',fig.cap="\\label{fig:Silh}Sélection du nombre de classes optimal",fig.pos='H'}
set.seed(1234)
Kmax<-10
reskmeanscl<-matrix(0,nrow=nrow(transData),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(transData,centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}
df<-data.frame(K=2:10,Iintra=Iintra)
g1 = ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")

# Silouhette
Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], dist(transData))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
g2 = ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")
grid.arrange(g1,g2,ncol=2)
```

D'après la figure \ref{fig:Silh}, on observe un coude marqué à 3 ou 4 classes pour l'inertie intraclasse. Dilhouette indique un nombre optimal de classes égal à 2. Cependant, nous optons pour 4 classes, car la projection des individus obtenue par l'ACP révèle une distinction claire entre 4 groupes, ce qui facilite une interprétation pertinente de chaque classe.


```{r kmeans, echo=F, fig.height=3,fig.align='center',fig.cap="\\label{fig:kmeans}Clustering à 4 classes avec Kmeans",fig.pos='H'}
reskmeans<-kmeans(transData,centers = 4)
fviz_cluster(reskmeans,transData,ellipse.type = "norm",repel=T,labelsize = 7)
```

Sur la figure \ref{fig:kmeans}, on observe :

- Une première classe regroupant les traitements T1 appliqués à toutes les heures pour les deux réplicats.

- Une deuxième classe contenant T2 et T3 à 1h pour les deux réplicats, située très proche de la classe T1. Cela suggère qu'à 1h, les gènes n'ont pas eu suffisamment de temps pour réagir aux traitements, expliquant l'absence d'effet visible et leur proximité avec la classe T1.

- Une troisième classe, composée de T2 et T3 à 2h et 3h pour les deux réplicats. À ce stade, les gènes commencent à réagir progressivement aux traitements. Cette classe se positionne à mi-chemin entre les classes avec une faible réaction et celle présentant une réaction significative.

- Une quatrième classe, contenant T2 et T3 à des heures supérieures à 4h, où les gènes réagissent aux traitements, montrant un effet significatif.

### Modèles de mélange 

Nous nous intéressons ici à la méthode des mélanges gaussiens, basée sur l'hypothèse que les gènes suivent une distribution de probabilité composée de plusieurs distributions gaussiennes : 
$$
f(.|\theta_K) = \sum_{k=1}^K \pi_k f_k(.|\alpha_k)
$$ 
Pour sélectionner le bon modèle, nous optons pour le critère de sélection \texttt{ICL}, défini par : 
$$
\text{crit}(K) = L(x|\hat{\theta}_K) - \frac{\nu_K}{2} \ln(n) - \text{Ent}(K)
$$
Nous utilisons les coordonnées issues de l'ACP comme matrice de données pour classer les variables $T_ts_HR_r$. Ce choix est motivé par la taille de la matrice de variance-covariance du jeu de données initial, qui est $p*p=2144*2144$. Une matrice aussi grande serait coûteuse en temps de calcul et ralentirait considérablement la convergence vers le mélange optimal. En utilisant les coordonnées principales, nous réduisons la dimension tout en préservant l'essentiel de l'information.

Nous gardons les 5 premières composantes principales ce qui représente plus de 95% de l’inertie.
```{r nb_classes_mel, echo=F}
Dataacp<-respca$ind$coord[,1:5]
resICLall = mclustICL(Dataacp,G=2:20)
summary(resICLall)
```
A partir des resultats observés, on va garder 8 classes de volume variant $(V)$, de même étendu $(E)$ et d'orientation libre $(V)$ puisque l'ICL correspondant est le maximum.

```{r mel,echo=F, fig.height=3,fig.align='center',fig.cap="\\label{fig:proba_boxplot}Les probabilités d'appartenance",fig.pos='H'}
modICL = Mclust(Dataacp, G = 8,modelNames = "VEV")
Aux = data.frame(label=paste("Cl",modICL$classification,sep=""),proba=apply(modICL$z,1,max))
ggplot(Aux,aes(x=label,y = proba)) + geom_boxplot()

classes_MEL = modICL$classification
classes_kmeans = reskmeans$cluster
table(classes_MEL,classes_kmeans)
```

Les points sont parfaitement classés, comme en témoigne la figure \ref{fig:proba_boxplot}. Toutes les probabilités d'appartenance sont à 1.

```{r lien,echo=F,fig.height=3,fig.align='center',fig.cap="\\label{fig:lien_mel_kmeans}Comparaison entre les classifications Kmeans et MEL",fig.pos='H'}
clust1<-paste("K-k",reskmeans$cluster,sep="")
clust2<-paste("MEL-k",modICL$classification,sep="")

Tab<-melt(table(clust1,clust2))
ggplot(Tab,aes(y=value,axis1=clust1,axis2=clust2))+
  geom_alluvium(aes(fill=clust1))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  theme(legend.position = "none")
```


La figure \ref{fig:lien_mel_kmeans} montre que les classes générées par le modèle de mélanges sont des sous-classes de celles définies par K-means, sans aucun chevauchement.

```{r mel_ACP,echo=F, fig.height=3,fig.align='center',fig.cap="\\label{fig:AcpVar_mel}Projection des individus classés par modèles de mélange",fig.pos='H'}
fviz_pca_ind(respca,col.ind=as.factor(modICL$classification),repel=T,labelsize = 2)
```

D'après la figure \ref{fig:AcpVar_mel}, on voit que le modèle de mélanges affine davantage la distinction entre les variables en segmentant les classes initiales en sous-classes plus spécifiques. Cette classification permet d'extraire davantage d'informations sur l'expression des gènes en fonction du traitement. Elle révèle que, dans une classe obtenue par k-means, il est possible d'identifier deux ou trois sous-classes présentant une expression similaire.

# Analyse des individus Gènes
## Partie ACP des individus


Nous nous intéressons ici aux individus. La figure \ref{fig:acp_ind} représente ces individus en fonction des var dans un espace réduit qui résume le mieux les données.


```{r, fig.pos='H', fig.align='center', echo=FALSE,fig.height=3,fig.cap="\\label{fig:acp_ind}Représentation des individus sur les axes principaux de l'ACP"}
pca_res_ind <- PCA(Data, scale.unit = FALSE, graph = FALSE)
pca_res_ind_scaled <- PCA(Data, scale.unit = TRUE, graph = FALSE)
g1 <- fviz_pca_ind(pca_res_ind, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
g2 <- fviz_pca_var(pca_res_ind, col.var = "blue", arrows = TRUE)

grid.arrange(g1, g2, ncol = 2, widths=c(3,1))
```
Ce graphique met en évidence la formation de deux groupes distincts de gènes, répartis de part et d'autre du premier axe principal. Ce premier axe est celui qui sépare le mieux les gènes, indiquant que les deux groupes contiennent des gènes présentant des profils d'expression très différents. Les gènes proches sur le graphique ont des profils d'expression similaires, tandis que ceux éloignés montrent des différences significatives. La coloration des points, basée sur le \texttt{cos2}, reflète la qualité de la projection des gènes : les couleurs chaudes indiquent une meilleure qualité de projection, ce qui signifie que ces gènes contribuent davantage à la variance expliquée dans cet espace réduit. Le cercle de corrélation nous montre que les traitements \( t \in \{\text{T}_2, \text{T}_3\} \), pour le réplicat \( r \in \{\text{R}_1, \text{R}_2\} \), et au temps \( s \in \{3\text{h}, 4\text{h}, 5\text{h}, 6\text{h}\} \) sont fortement corrélés à l'axe 1. On en déduit que cet axe correspond à l'expression des gènes, avec les gènes surexprimés à droite et les gènes sous-exprimés à gauche.

## Clustering K-means 

Tout d'abord, nous utiliserons la méthode \texttt{k-means} pour étudier le clustering des individus. 

La figure \ref{fig:inertie_silhou} permet de déterminer le nombre optimal de clusters en analysant l'évolution de l'inertie intra-classe et en utilisant le critère silhouette pour évaluer la qualité du clustering.

```{r, fig.pos='H', fig.align='center', echo=FALSE,fig.height=3,fig.cap="\\label{fig:inertie_silhou}Évolution de l'inertie intra-classe et du critère silhouette"}
set.seed(1234)
Kmax <- 15
reskmeanscl <- matrix(0, nrow = nrow(Data), ncol = Kmax - 1)
Iintra <- NULL

for (k in 1:Kmax) {
  resaux <- kmeans(Data, k, nstart = 1)
  reskmeanscl[, k - 1] <- resaux$cluster
  Iintra <- c(Iintra, resaux$tot.withinss)
}

df <- data.frame(K = 1:15, Iintra = Iintra)
g_intra = ggplot(df, aes(x = K, y = Iintra)) +
  geom_line() +
  geom_point() +
  xlab("Nombre de clusters") +
  ylab("Inertie intraclasse")

Silhou <- NULL
for (k in 2:Kmax) {
  aux <- silhouette(kmeans(Data, k)$cluster, daisy(Data))
  Silhou <- c(Silhou, mean(aux[, 3]))
}

df <- data.frame(K = 2:Kmax, Silhouette = Silhou)
g_silhou = ggplot(df, aes(x = K, y = Silhouette)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "bottom")

aux <- silhouette(kmeans(Data, centers = which.max(Silhou) + 1)$cluster, daisy(Data))
grid.arrange(g_intra, g_silhou, ncol=2)

```

La figure de gauche représente l'évolution de l'inertie intra-classe, qui diminue à mesure que le nombre de clusters augmente. Cependant, lorsque le nombre de clusters atteint un certain seuil, l'inertie devient stable et ne diminue plus de manière significative. Le point de coude dans le graphique nous aide à identifier le nombre optimal de clusters. Dans ce cas, le coude se forme lorsque le nombre de clusters est égal à 4, ce qui suggère que 4 clusters représentent le meilleur compromis entre la compacité des groupes et la simplicité du modèle.

La courbe de l'évolution du critère silhouette montre que le nombre optimal de clusters est égal à 2. Cependant, le critère silhouette est basé sur une moyenne, ce qui signifie qu'il peut être sensible à la présence d'outliers, et dans ce cas, il peut attribuer des clusters incorrects.

Nous pouvons maintenant représenter les individus dans l'espace réduit de l'ACP et les afficher selon leur cluster.
La figure \ref{fig:k_means_ind} représente les individus selon leur cluster dans l'espace réduit de l'ACP.


```{r, echo=FALSE, include=FALSE}
reskmeans<-kmeans(Data, 4)  
reskmeans$cluster
fviz_cluster(reskmeans, data=Data,ellipse=F,geom=c("point"))
```

```{r, fig.pos='H', fig.align='center', fig.height=3,echo=FALSE,fig.cap="\\label{fig:k_means_ind}Clusters représentés sur les axes principaux"}
fviz_pca_ind(pca_res_ind, col.ind=as.factor(reskmeans$cluster), geom="point")
```


## Clustering Hiérarchique (HAC)


Dans cette partie, nous allons mettre en place une classification hiérarchique ascendante. La méthode \texttt{Euclidienne} utilisée pour calculer la distance entre les gènes est la distance \texttt{k-means} définie par : 
$$
d(x_i, x_\ell) = \|x_i - x_\ell\|_2 = \sqrt{\sum_{j=1}^p (x_{ij} - x_{\ell j})^2}
$$
Pour l'agrégation des clusters, nous optons pour la mesure d'agrégation \texttt{Le lien complet}, donnée par : 
$$
D(C_k, C_{k'}) = \frac{|C_k| \, |C_{k'}|}{|C_k| + |C_{k'}|} \, d(m_k, m_{k'})^2 \quad \text{où} \quad m_k \, (\text{resp. } m_{k'}) \text{ est le centre de gravité de } C_k \, (\text{resp. } C_{k'})
$$
Pour déterminer le nombre de clusters, nous introduisons le critère \texttt{Calinski-Harabasz} donné par : 
$$
\quad \text{PseudoF}(K) = \frac{I_{\text{inter}}(P_K)}{K - 1} \Big/ \frac{I_{\text{intra}}(P_K)}{n - K}
$$

La figure \ref{fig:deno_ind} ci-dessous représente le clustering hiérarchique, permettant de créer un dendrogramme et de déterminer les clusters en coupant l'arbre à un niveau spécifique.


```{r, fig.pos='H', fig.align='center', fig.cap="\\label{fig:deno_ind}Evolution du critère CH et Dendrogramme avec 2 clusters", fig.height=3, echo=FALSE}
library(ggdendro)
hclust_res <- hclust(dist(Data, method = "euclidean"))
dendro_data <- dendro_data(hclust_res)
g2 <- ggplot(segment(dendro_data)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) +
  theme_minimal() +
  ggtitle("Dendrogramme")

CH<-NULL
Kmax<-15
for (k in 2:Kmax){
  CH<-c(CH,index.G1(Data,cl = cutree(hclust_res, k)))
}
daux<-data.frame(NbClust=2:Kmax,CH=CH)
g1 <- ggplot(daux,aes(x=NbClust,y=CH))+geom_line()+geom_point()
grid.arrange(g1, g2, ncol = 2)
```
L'analyse de l'indice \texttt{Calinski-Harabasz} montre que 4 clusters maximisent ce critère. Le dendrogramme montre que les groupes de gènes qui se fusionnent tôt ont des profils d'expression très similaires, tandis que ceux qui se rejoignent plus tard présentent des différences plus marquées. La figure \ref{fig:deno} représente les individus classés par la méthode hiérarchique ascendante selon leur cluster dans l'espace réduit de l'ACP.


```{r, fig.pos='H', fig.align='center', fig.cap="\\label{fig:deno}Clusters représentés sur les axes principaux", fig.height=3, echo=FALSE}
Class <- cutree(hclust_res, k = 2)
fviz_pca_ind(pca_res_ind, geom = c("point"), habillage = as.factor(Class))
```

## Mélange gaussien
Comme on sait que l'expression des gènes est dépendante, on peut d'ores et déjà retenir que les modèles permettant des degrés variés de liberté sont les plus adaptés. On en déduit que seuls les modèles suivants sont retenus (\texttt{modelNames}) :

```{r, fig.pos='H', fig.align='center', echo=TRUE, eval=FALSE}
mg_res <- mclustICL(Data, G=2:20, modelNames = c("EVE", "EEV", "EVV", "VEV", "VVV"))
```

```{r, fig.pos='H', fig.height=3, echo=FALSE}
table_data <- data.frame(
  "Best ICL values" = c("VEV,4", "VVV,4", "VEV,5"),
  "ICL" = c(-61554.37, -61722.510, -63474.420),
  "ICL diff" = c(0.00, -168.143, -1920.053)
)
table_data
```
```{r, echo=FALSE}
mg_res <- Mclust(Data, G=4, modelNames = "VEV")
```


Le modèle maximisant le critère \texttt{ICL} est "VEV", avec un nombre de clusters égal à 4. La figure \ref{fig:mmacp} suivante représente les clusters obtenus des individus.


```{r, fig.pos='H', fig.align='center', fig.height=3, echo=FALSE, fig.cap="\\label{fig:mmacp}Clusters représentés avec un Mélange Gaussien"}
fviz_cluster(mg_res, data = Data, ellipse = TRUE, geom = "point", main = "Clustering avec Mélange Gaussien (ICL)")
```

### Comparaison des différents algorithmes

#### Diagramme d'alluvion :

Nous allons ici comparer les trois méthodes de clustering réalisées précédemment en utilisant un diagramme d'alluvions (figure \ref{fig:alluvion}).

```{r, fig.pos='H', fig.align='center', fig.height=3, fig.cap="\\label{fig:mmacp}Diagramme d'alluvions", echo=FALSE}
clust1 <- paste("K-k", reskmeans$cluster, sep = "")
clust2 <- paste("CH-k", cutree(hclust_res, k = 2), sep = "")
clust3 <- paste("MG-k", mg_res$classification, sep = "")

Tab <- melt(table(clust1, clust2, clust3))
ggplot(Tab, aes(y = value, axis1 = clust1, axis2 = clust2, axis3 = clust3)) +
  geom_alluvium(aes(fill = clust1)) +
  geom_stratum(width = 1 / 12) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme(legend.position = "none")
```

La première observation marquante est le flux important partant du cluster 1 des \texttt{k-means} vers le cluster 1 de la classification hiérarchique, et se terminant dans les clusters 1, 2 et 4 du mélange gaussien. Les classes obtenues via la classification hiérarchique sont une agrégation des classes de \texttt{k-means}. On en déduit qu'elles sont concordantes.  


### MCA sur les différentes méthodes :

Une autre méthode de comparaison consiste à créer un tableau disjonctif complet qui présente, pour chaque gène, les clusters obtenus selon les trois méthodes de clustering : \texttt{k-means}, classification hiérarchique et mélanges gaussiens.


```{r, fig.pos='H', fig.align='center', fig.height=3, echo=FALSE, eval=FALSE, include=FALSE}
library(kableExtra)
table_kmeans <- table(reskmeans$cluster)
table_hclust <- table(cutree(hclust_res, k = 2))
table_mg <- table(mg_res$classification)

table_kmeans_df <- as.data.frame(table_kmeans)
table_hclust_df <- as.data.frame(table_hclust)
table_mg_df <- as.data.frame(table_mg)

colnames(table_kmeans_df) <- c("Cluster", "Nombre d'éléments")
colnames(table_hclust_df) <- c("Cluster", "Nombre d'éléments")
colnames(table_mg_df) <- c("Cluster", "Nombre d'éléments")

kable(table_kmeans_df, col.names = c("Cluster", "Nombre d'éléments"), caption = "Tableau des tailles des clusters - K-means") 
kable(table_hclust_df, col.names = c("Cluster", "Nombre d'éléments"), caption = "Tableau des tailles des clusters - Classification hiérarchique")
kable(table_mg_df, col.names = c("Cluster", "Nombre d'éléments"), caption = "Tableau des tailles des clusters - Mélanges Gaussiens")

```


```{r, fig.pos='H', fig.align='center', echo=FALSE, fig.height=3, fig.cap="\\label{fig:mca_ind}Représentation des modalités sur les axes principaux de la MCA",}
Kmeans = as.factor(reskmeans$cluster) 
Melange = as.factor(mg_res$classification)  
CAH = as.factor(cutree(hclust_res, k = 2)) 

df.clustering = data.frame(
  Kmeans = Kmeans,
  Melange = Melange,
  CAH = CAH
)

resMCA <- MCA(df.clustering, graph = FALSE) 
habillage_var <- ifelse(grepl("Kmeans", rownames(resMCA$var$coord)), "Kmeans",
                        ifelse(grepl("Melange", rownames(resMCA$var$coord)), "Melange", "CAH"))

g1 <- fviz_mca_var(resMCA,
             col.var = habillage_var,  
             repel = TRUE,  
             title = "MCA - Visualisation des Méthodes de Clustering",
             ggtheme = theme_minimal())  

g2 <- fviz_mca_var(resMCA, choice = "mca.cor",
             repel = TRUE,
             ggtheme = theme_minimal(),
             title = "MCA - Corrélations des Méthodes de Clustering")
grid.arrange(g1, g2, ncol=2, widths=c(2,1))
```

La première dimension de la figure \ref{fig:mca_ind} est associée aux trois méthodes, tandis que la deuxième dimension semble être principalement influencée par \texttt{k-means} et le mélange gaussien. Les proximités observées entre les modalités sur le plan révèlent une forte association entre elles. Par exemple, on constate que le cluster 1 obtenu par \texttt{k-means} et le cluster 1 de la méthode hiérarchique sont très proches, ce qui suggère que plusieurs gènes classés dans le cluster 1 de \texttt{k-means} se retrouvent également dans le cluster 1 de la méthode hiérarchique. Cette observation confirme la comparaison réalisée à l'aide du diagramme d'alluvions.

# Etude des différences entre les deux réplicats

## Comparaison Statistique des Lois de Probabilité des Deux Réplicats

Dans cette partie, nous allons appliquer le \texttt{test de Kolmogorov-Smirnov (KS)}, un test statistique non paramétrique qui permet de comparer deux distributions de probabilité empiriques ou une distribution empirique avec une distribution théorique. La statistique de test est définie par :

\[
D_{n,m} = \sup_{t \in \mathbb{R}} |\hat{F}_n(t) - \hat{G}_m(t)|
\]

où $\hat{F}_n(t)$ et $\hat{G}_m(t)$ représentent les fonctions de répartition empiriques respectives des deux échantillons. Sous l'hypothèse nulle $H_0 : F = G$, où $F$ et $G$ désignent les fonctions de répartition des deux populations, la distribution de $D_{n,m}$ est indépendante de $F$ si $F$ est continue.

```{r, echo=FALSE}
replicat1 <- as.vector(unlist(Data[, c(1:18)]))
replicat2 <- as.vector(unlist(Data[, c(19:36)]))
```

```{r, echo=FALSE, fig.height=3, fig.pos='H', fig.align='center', fig.cap="\\label{fig:comp_r12}Comparaison des deux réplicats"}
df_replicats <- data.frame(
  value = c(replicat1, replicat2),
  replicat = factor(rep(c("Réplicat 1", "Réplicat 2"), c(length(replicat1), length(replicat2))))
)

ggplot(df_replicats, aes(x = value, fill = replicat, color = replicat)) +
  geom_density(alpha = 0.4, size = 1.2) +  
  scale_fill_manual(values = c("blue", "red")) + 
  scale_color_manual(values = c("blue", "red")) +
  labs(title = "Comparaison des réplicats", x = "Valeur", y = "Densité") +  
  theme_minimal() +  
  theme(legend.position = "top")  
```
La figure \ref{fig:comp_r12} represente le graphique de densité comparatif qui permet de visualiser les distributions des deux réplicats. Les hypothèses du test sont les suivantes : 
\begin{itemize}
    \item $H_0$ : Les deux réplicats  comparés suivent la même loi de probabilité.
    \item $H_1$ : Les lois de probabilité des deux réplicats  comparés sont différentes.
\end{itemize}

```{r, fig.pos='H', fig.align='center', echo=FALSE}
ks_test_result <- ks.test(replicat1, replicat2)
ks_test_result
```
Rejet de H0 : Les lois de probabilité des deux réplicats sont significativement différentes (p-value = p-value = 1.111068e-32)

## Analyse de Significativité des Lois de Probabilité pour chaque Traitement pris séparément

Ici, nous étudions si les sous-groupes de traitements (\texttt{T1, T2, T3}) sont significativement différents. Nous interpréterons la statistique de test obtenue et sa région critique en fonction du niveau de signification choisi.

```{r, fig.pos='H', fig.align='center', echo=FALSE}
T1_R1 <- as.vector(unlist(Data[, c(1,6)]))
T1_R2 <- as.vector(unlist(Data[, c(19,24)]))
T2_R1 <- as.vector(unlist(Data[, c(7,12)]))
T2_R2 <- as.vector(unlist(Data[, c(25,30)]))
T3_R1 <- as.vector(unlist(Data[, c(13,18)]))
T3_R2 <- as.vector(unlist(Data[, c(31,36)]))

ks.test(T1_R1, T1_R2)
```
Rejet de H0 : Les lois de probabilité des deux réplicats pour T1 sont significativement différentes (p-value = 1.143769e-14 ).

```{r, fig.pos='H', fig.align='center', echo=FALSE}
ks.test(T2_R1, T2_R2)
```
Rejet de H0 : Les lois de probabilité des deux réplicats pour T2 sont significativement différentes (p-value = 7.358161e-12 ).

```{r, fig.pos='H', fig.align='center', echo=FALSE}
ks.test(T3_R1, T3_R2)
```

Rejet de H0 : Les lois de probabilité des deux réplicats pour T3 sont significativement différentes (p-value = 7.112548e-17 ).


En somme, l'ensemble des tests de Kolmogorov-Smirnov a conduit au rejet systématique de l'hypothèse nulle (\(H_0\)) pour tous les traitements (\(T1, T2, T3\)). Cela signifie que les distributions des deux réplicats (\(R1\) et \(R2\)) sont significativement différentes pour chaque traitement.


## Effet combiné du temps et du traitement 

Nous cherchons à étudier l’effet combiné du temps et du traitement sur la différence des deux réplicats. Pour ce faire, nous définissons une nouvelle variable \( Y_{tsg} \) :
$$
Y_{tsg} = Y_{tsgR1} - Y_{tsgR2}, t\in\{1,\ldots,3\} ,\ s\in\{1,\ldots,6\} ,\ g\in\{1,\ldots,2144\}.
$$
L'objectif est de modéliser cette variable en fonction de deux facteurs principaux : le temps (variable quantitative) et le traitement (variable qualitative).

Pour ce faire, nous utilisons un \textbf{modèle ANCOVA avec interaction}, qui permet de modéliser la relation entre la variable dépendante \( Y_{tsg} \) et les deux facteurs (temps et traitement), ainsi que leur interaction.
$$
Y_{tsg} = \beta_0 + \beta_1 \cdot Temps + \beta_2 \cdot Traitement + \beta_3 \cdot (Temps \times Traitement) + \epsilon_{tsg} 
$$
- Temps : Variable quantitative représentant le temps.

- Traitement : est une variable indicatrice (0 ou 1) indiquant si le gène a été soumis au traitement.

- Les coefficients $\beta$ représentent les effets respectifs de l'ordonnée à l'origine, du temps, du traitement et de l'interaction entre le temps et le traitement.

- $\epsilon_{tsg}$ est un terme d'erreur aléatoire.

```{r modele_ANCOVA,echo=F}
# Etape 1 : On effectue la différence des réplicats
p = ncol(Data)

Data_Diff_R = Data[,1:(p/2)] - Data[,((p/2) + 1):p]
colnames(Data_Diff_R) <- sub("_[^_]*$", "", colnames(Data[,1:(p/2)]))

#Etape 2 : Création de Yij de telle sorte que Y_ij = Y_tsg
Y = as.vector(as.matrix(Data_Diff_R))

#Etape 3 : Création des noms de lignes du vecteur Y
noms_Y <- outer(colnames(Data_Diff_R), rownames(Data_Diff_R), paste, sep="_")
noms_Y <- as.vector(t(noms_Y))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)
temps <- as.numeric(sapply(strsplit(noms_Y, "[_h]"), function(x) x[2]))

# Etape 5 : Création du tableau pour le modèle linéaire
matrix = as.data.frame(cbind(Y, traitement, temps))
matrix$temps <- as.numeric(matrix$temps)
matrix$Y <- as.numeric(matrix$Y)

rownames(matrix) <- noms_Y
```


```{r Model, echo=F}
ML <- lm(Y~traitement*temps, data = matrix)
summary(ML)$coefficients
```

On observe :

- L'intercept est significatif.

- T2 et T3 seuls ne sont pas significativement différents du traitement de référence.

- Le temps seul n'est pas significatif.

- L'interaction T3:temps est hautement significative, ce qui indique que pour T3, l'effet du temps est très important et influence fortement la réponse.

Pour vérifier l'optimalité de notre modèle, nous établissons le modèle additif sans intéraction.
$$
Y_{tsg} = \beta_0 + \beta_1 \cdot Temps + \beta_2 \cdot Traitement + \epsilon_{tsg} 
$$

```{r Model_sans_inter, echo=F,include=F}
ML_no_inter = lm(Y~traitement+temps,data=matrix)
summary(ML_no_inter)$coefficients
```

Avant de procéder au test de sous-modèle pour déterminer si le modèle avec interaction doit être conservé, nous comparons les valeurs prédites des deux modèles en les visualisant graphiquement.

```{r courbe_inter,echo=F, fig.height=3,fig.align='center',fig.cap="\\label{fig:interaction}Interaction plot",fig.pos='H'}
# Modèle sans interaction
M_non_interaction <- lm(Y ~ traitement + temps, data = matrix)

# Modèle avec interaction
M_interaction <- lm(Y ~ traitement * temps, data = matrix)

# Création des nouvelles données pour prédiction
new_data <- expand.grid(
  traitement = unique(matrix$traitement),
  temps = seq(min(matrix$temps), max(matrix$temps), length.out = 100)
)

# Prédictions
new_data$Y_non_interaction <- predict(M_non_interaction, newdata = new_data)
new_data$Y_interaction <- predict(M_interaction, newdata = new_data)

# Graphique pour le modèle sans interaction
plot_non_interaction <- ggplot(new_data, aes(x = temps, y = Y_non_interaction, color = traitement)) +
  geom_line(size = 1) +
  labs(title = "Modèle sans interaction",
       x = "Temps",
       y = "Valeurs prédites de Y",
       color = "Traitement") +
  theme_minimal()

# Graphique pour le modèle avec interaction
plot_interaction <- ggplot(new_data, aes(x = temps, y = Y_interaction, color = traitement)) +
  geom_line(size = 1) +
  labs(title = "Modèle avec interaction",
       x = "Temps",
       y = "Valeurs prédites de Y",
       color = "Traitement") +
  theme_minimal()

# Affichage côte à côte
grid.arrange(plot_non_interaction, plot_interaction, ncol = 2)
```

D'après la figure \ref{fig:interaction}, on observe que dans le modèle sans interaction, les courbes sont parallèles, reflétant l'absence d'interdépendance entre le traitement et le temps. En revanche, dans le modèle avec interaction, les courbes montrent des variations de pente ou des croisements, indiquant une présence probable d'interaction entre ces deux variables. À partir de ces deux représentations, un test de sous-modèle est effectué pour déterminer si l'interaction doit être conservée dans le modèle final.

```{r Compare_modeles, echo=F}
anova(ML_no_inter,ML)
```
La p-valeur obtenue est de $1.426e-15<0.05$. Cela conduit à rejeter largement l'hypothèse nulle et à privilégier le modèle avec interaction.

# Etude de la dynamique de l’expression des gènes 
## Pédiction de l’expression des gènes à 6h à partir de l'expression à 1h

Nous avons calculé la moyenne des réplicats pour chaque gène et chaque temps, notée $Y_{tsgMoy}$. Un modèle ANCOVA avec interaction a été ajusté pour prédire l'expression finale (à t=6h) en fonction de l'expression initiale (à t=1h) et du traitement :
$$
Y_{t6hgMoy} = \beta_0 + \beta_1 \cdot Y_{t1hgMoy} + \beta_2 \cdot Traitement + \beta_3 \cdot (Y_{t1hgMoy} \times Traitement) + \epsilon_{tsg}
$$
où :

- $Y_{t6hgMoy}$ est l'expression moyenne du gène g au temps t=6h.

- $Y_{t1hgMoy}$ est l'expression moyenne du gène g au temps t=1h (expression initiale).

- Traitement : est une variable indicatrice (0 ou 1) indiquant si le gène a été soumis au traitement.

- Les coefficients $\beta$ représentent les effets respectifs de l'ordonnée à l'origine, de l'expression initiale, du traitement et de l'interaction entre l'expression initiale et le traitement.

- $\epsilon_{tsg}$ est un terme d'erreur aléatoire.
```{r Ancova_6h_1h,echo=F}
# extraire les Y à 1h et créer une matrice
p = ncol(Data)
Data_moy_R = (Data[,1:(p/2)] + Data[,((p/2) + 1):p])/2
Data_moy_R_1h = Data_moy_R[,c(1,7,13)]
Data_moy_R_6h = Data_moy_R[,c(6,12,18)]

colnames(Data_moy_R_1h) <- sub("_[^_]*$", "", colnames(Data_moy_R_1h))


colnames(Data_moy_R_6h) <- sub("_[^_]*$", "", colnames(Data_moy_R_6h))


Y_moy_1h = as.vector(as.matrix(Data_moy_R_1h))
Y_moy_6h = as.vector(as.matrix(Data_moy_R_6h))

#Etape 3 : Création des noms de lignes du vecteur Y
noms_Y <- outer(colnames(Data_moy_R_1h), rownames(Data_moy_R_1h), paste, sep="_")
noms_Y <- as.vector(t(noms_Y))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)

# Etape 5 : Création du tableau pour le modèle linéaire
matrixMoy = as.data.frame(cbind(Y_moy_6h, Y_moy_1h, traitement))
matrixMoy$Y_moy_1h <- as.numeric(matrixMoy$Y_moy_1h)
matrixMoy$Y_moy_6h <- as.numeric(matrixMoy$Y_moy_6h)
```

```{r Model_6h_1h,echo=F}
M_1h_to_6h <- lm(Y_moy_6h~Y_moy_1h*traitement, data = matrixMoy)
summary(M_1h_to_6h)
```

Nous traçons deux graphes qui nous aideront à déterminer la qualité de l'ajustement du modèle :

```{r observed_fitted_plot,echo=F,fig.height=3,fig.align='center',fig.cap="\\label{fig:obsVSpred1}Repésentation de la qualité du modèle",fig.pos='H'}
# Prédictions à partir du modèle
matrixMoy$Predicted <- predict(M_1h_to_6h, newdata = matrixMoy)

# Tracé des valeurs observées (Y_moy_6h) par rapport aux valeurs prédites
g1 = ggplot(matrixMoy, aes(x = Predicted, y = Y_moy_6h)) +
  geom_point(aes(color = traitement), alpha = 0.6) +  # Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
fitted_vals <- fitted(M_1h_to_6h)
residuals <- resid(M_1h_to_6h)
g2 = ggplot(data = data.frame(Fitted = fitted_vals, Residuals = residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "blue", alpha = 0.6) + # Points des résidus
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + # Ligne à y = 0
  theme_minimal() + # Thème esthétique minimal
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
grid.arrange(g1,g2,ncol=2)
```

D'après la figure \ref{fig:obsVSpred1}, on observe :

- les valeurs prédites sont principalement proches de 0, tandis que les valeurs observées, en particulier pour les traitements T2 et T3, diffèrent significativement de 0. Cela suggère que l'expression des gènes à 1h ne constitue pas un bon indicateur pour prédire celle à 6h.
En effet, 1 heure représente un stade relativement précoce, et les gènes n'ont probablement pas eu suffisamment de temps pour réagir aux traitements.

- le graphique des résidus en fonction des valeurs ajustées, on constate que La dispersion non uniforme des résidus suggère une hétéroscédasticité: la variabilité des erreurs n'est pas constante. De plus, la légère tendance non-linéaire des résidus indique que la relation entre les variables pourrait être plus complexe que ce que notre modèle linéaire simple ne capture.
En d'autres termes, le modèle que nous utilisons actuellement ne semble pas être le plus adapté à nos données.

**Conclusion**:
Le modèle ajusté montre une qualité d'ajustement modérée, avec un R² de 27.06%. Les termes d’interaction entre $Y_{1h}$ et le traitement sont significatifs (p<2e−16), ce qui montre que l’effet de $Y_{1h}$ sur $Y_{6h}$ varie selon le traitement. 
En se basant sur les graphiques obtenus, le modèle que nous utilisons actuellement ne semble pas être le plus adapté à nos données. Des ajustements sont nécessaires pour obtenir des résultats plus fiables.

## A partir de l'expressions des gènes à 3h
Nous souhaitons prédire $Y_{6hMoy}$ en utilisant $Y_{3hMoy}$. Pour ce faire, nous allons reprendre le modèle précédent et l'adapter en remplaçant toutes les variables correspondant aux données au temps $1h$ par leurs équivalents au temps $3h$. 
```{r Ancova_6h_3h,echo=F}
p = ncol(Data)

Data_moy_R_3h = Data_moy_R[,c(3,9,15)]

colnames(Data_moy_R_3h) <- sub("_[^_]*$", "", colnames(Data_moy_R_3h))

Y_moy_3h = as.vector(as.matrix(Data_moy_R_3h))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)

# Etape 5 : Création du tableau pour le modèle linéaire
matrixMoy2 = as.data.frame(cbind(Y_moy_6h, Y_moy_3h, traitement))
matrixMoy2$Y_moy_6h <- as.numeric(matrixMoy2$Y_moy_6h)
matrixMoy2$Y_moy_3h <- as.numeric(matrixMoy2$Y_moy_3h)

```
```{r Model_6h_3h, echo=F}
M_3h_to_6h <- lm(Y_moy_6h~Y_moy_3h*traitement, data = matrixMoy2)
summary(M_3h_to_6h)
```

Le modèle basé sur les données de 3h semble être plus performant que celui de 1h, avec un R² ajusté presque trois fois supérieur et un RSE significativement plus faible. Cela pourrait signifier que les valeurs à 3h prédisent mieux les valeurs à 6h.

On trace la courbe des valeurs observées par rapport aux valeurs prédites, ainsi que les résidus par rapport aux valeurs prédites.

```{r observed_fitted,echo=F,fig.height=3,fig.align='center',fig.cap="\\label{fig:obsVSpred2}Repésentation de la qualité du modèle",fig.pos='H'}
# Prédictions à partir du modèle
matrixMoy2$Predicted <- predict(M_3h_to_6h, newdata = matrixMoy2)

# Tracé des valeurs observées (Y_moy_6h) par rapport aux valeurs prédites
library(ggplot2)
g1 = ggplot(matrixMoy2, aes(x = Predicted, y = Y_moy_6h)) +
  geom_point(aes(color = traitement), alpha = 0.6) +  # Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
new_fitted_vals <- fitted(M_3h_to_6h)
new_residuals <- resid(M_3h_to_6h)
g2 = ggplot(data = data.frame(Fitted = new_fitted_vals, Residuals = new_residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "blue", alpha = 0.6) + # Points des résidus
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + # Ligne à y = 0
  theme_minimal() + # Thème esthétique minimal
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
grid.arrange(g1,g2,ncol=2)
```

A partir de la figure \ref{fig:obsVSpred2} on observe que les valeurs prédites s'alignent bien avec les valeurs observées, et que les résidus sont plus uniformément dispersés autour de 0. Cela indique une amélioration notable de la qualité des prédictions par rapport au modèle précédent.

# Etude de l’expression des gènes pour le traitement T3 à 6h :
## Les variables prédictives pour le traitement T3 à 6h parmi les différents temps observés pour les traitements T1 et T2

Nous allons réaliser une regression linéaire pour prédire les gènes du traitement 3 à 6h en fonction des gènes des autres traitements à toutes les heures.  

```{r Reg, echo = F , fig.cap="Modèle de regression linéaire complet"}
# Matrice moyenne des replicats
p = ncol(Data)
Moy_Rep = (Data[,1:(p/2)] + Data[,((p/2) + 1):p])/2
colnames(Moy_Rep) <- sub("_[^_]*$", "", colnames(Data[,1:(p/2)]))

modele_T3_all <- lm(T3_6h ~ T1_1h + T1_2h + T1_3h + T1_4h + T1_5h + T1_6h +
                      T2_1h + T2_2h + T2_3h + T2_4h + T2_5h + T2_6h, 
                    data = Moy_Rep)
summary(modele_T3_all)
```

On remarque dans cette sortie, que la p-valeur pour le modèle constant est < 2.2e-16, on rejette le modèle constant. On se demande maintenant quelle est la meilleur modèle qu'on puisse établir. Pour selectionner le modèle parcimonieux, on décide d'utiliser le critère de Mallows avec une méthode backward. On cherche à minimiser ce critère.

```{r Selection, fig.height=4,echo=F, fig.align = "center", fig.cap = "\\label{fig:critereMallows}Critère de Mallows",fig.pos='H'}
choix = regsubsets(T3_6h~T1_1h + T1_2h + T1_3h + T1_4h + T1_5h + T1_6h +
                      T2_1h + T2_2h + T2_3h + T2_4h + T2_5h + T2_6h,data=Moy_Rep,nbest=1,nvmax=11,method="backward")
plot(choix,scale="Cp")
```

Sur la Figure \ref{fig:critereMallows}, on remarque le critère $Cp$ selectionne toutes les variables sauf T1_5h et T2_1h. On décide de tester ce sous-modèle en le comparant au modèle de regression linéaire complété implémenté précédemment. 

```{r Selection2, echo=F, fig.show='hold', fig.align = "center", fig.cap = " "}
new_modele_T3_all <- lm(T3_6h ~ T1_1h + T1_2h + T1_3h + T1_4h + T1_6h +
                      T2_2h + T2_3h + T2_4h + T2_5h + T2_6h, 
                    data = Moy_Rep)
anova(new_modele_T3_all,modele_T3_all)
```

Pour l'analyse de variable entre les 2 modèles, on obtient une p-valeur = 0.8284 > 0.05, on accepte donc le sous-modèle. 

On souhaîte maintenant vérifier si notre nouveau modèle permet de bien prédire les expression des gènes à 6h.


```{r predict, echo = F, fig.width=3,fig.height=2, fig.cap="\\label{fig:comp_vop}Comparaison valeurs observées et prédites",fig.pos='H'}
tmp = Moy_Rep
tmp$Predicted <- predict(new_modele_T3_all, newdata = tmp)
ggplot(tmp, aes(x = Predicted, y = T3_6h)) +
  geom_point() +# Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
new_fitted_vals <- fitted(new_modele_T3_all)
new_residuals <- resid(new_modele_T3_all)
ggplot(data = data.frame(Fitted = new_fitted_vals, Residuals = new_residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "blue", alpha = 0.6) + # Points des résidus
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + # Ligne à y = 0
  theme_minimal() + # Thème esthétique minimal
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
```


Sur la figure \ref{fig:comp_vop}, on observe une répartition linéaire des points suivant la droite $y=x$, indiquant une forte concordance entre les valeurs prédites et observées. Cela suggère que notre modèle prédit efficacement l’expression des gènes à 6h.

## Prédiction des gènes sur-exprimés et des gènes sous-exprimés à 6h pour le traitement 3 à partir des traitements T1 et T2 et les heures 1 à 3 pour ces mêmes gènes
Nous allons utiliser un modèle linéaire généralisé pour prédire l’expression des gènes, car la variable cible est binaire : un gène peut être soit sous-exprimé ($Y=0$), soit sur-exprimé ($Y=1$). Pour cela, nous appliquons une régression logistique en choisissant la fonction de lien logit, qui est définie comme suit :
$$
\text{logit}(p) = \log \left( \frac{p}{1 - p} \right)
$$
où $p$ représente la probabilité qu’un gène soit sur-exprimé.

L’équation de notre modèle est donc la suivante :
$$
\log \left( \frac{P(Y_{6hMoy} = 1)}{1 - P(Y_{6hMoy} = 1)} \right) = \beta_0 + \beta_1 Y_{T1,1h} + \beta_2 Y_{T1,2h} + \beta_3 Y_{T1,3h} + \beta_4 Y_{T2,1h} + \beta_5 Y_{T2,2h} + \beta_6 Y_{T2,3h}
$$
où $Y_{Tt,sh}$ représente l’expression du gène sous le traitement $Tt$ à l’instant $sh$.

```{r MLG, echo=F}
# Filtrer les données en excluant les valeurs intermédiaires (-1 <= T3_6h <= 1)
x = Moy_Rep[Moy_Rep$T3_6h < 1 & Moy_Rep$T3_6h > -1, ]
# 8 genes non classés
filtered_data <- Moy_Rep[Moy_Rep$T3_6h < -1 | Moy_Rep$T3_6h > 1, ]
# Définir la colonne target selon les critères donnés
filtered_data$target <- as.factor(ifelse(filtered_data$T3_6h > 1, 1, 0))
filtered_data <- filtered_data[, c("T1_1h", "T1_2h", "T1_3h", "T2_1h", "T2_2h", "T2_3h","target")]
```

```{r MLG_model, echo=F}
model <- glm(filtered_data$target ~. , data = filtered_data, family = "binomial")
summary(model)
```

On essaie ensuite de réduire les paramètres du modèle grace au critère AIC que l'on souhaîte minimiser. Pour cela, on utilise la commande suivant :

```{r, echo=T, eval = F}
step.backward = step(model, direction="backward",k=log(nrow(filtered_data)))
```

Les resultats nous donne un AIC de 422.59 pour un modèle prédit en fonction de T2_2h, T1_2h, T1_3h et T2_3h. On génère ensuite et compare ce nouveau modèle au modèle complet.

```{r, echo=F}
bestmodel = glm(filtered_data$target ~T2_2h + T1_2h +T1_3h + T2_3h , data = filtered_data, family = "binomial")
anova(bestmodel,model)
```

On obtient ici une p-valeur = 0.785 > 0.05, on accepte donc sous modèle.

Nous évaluons la performance de notre modèle de régression logistique en utilisant une courbe ROC (Receiver Operating Characteristic). Cette courbe permet d’analyser la capacité du modèle à distinguer correctement les classes en traçant le taux de vrais positifs contre le taux de faux positifs pour différents seuils de classification.

L’aire sous la courbe ROC (AUC) permet de quantifier la performance globale du modèle : plus l’AUC est proche de 1, meilleure est la capacité de discrimination du modèle.

```{r Roc,echo=F,fig.height=3,fig.align='center',fig.cap="\\label{fig:Roc}Courbe ROC",fig.pos='H'}
l<-1000
# pour ne pas prendre des données rangées pour le test (qui viennent apres ceux d'apprentissage)
perm<-sample(nrow(filtered_data))
# Echantillon d'apprentissage
dapp<-filtered_data[perm[1:l],]
# Echantillon test
dtest<-filtered_data[-perm[1:l],]
# Estimation du modèle sur l'échantillon d'apprentissage
modelapp<-glm(target ~. , family = "binomial",data=dapp)
# Prédictions sur l'échantillon test
prev<-predict(modelapp,newdata=dtest,type="response")


# Prédire sur les données de test ou validation
predictions <- predict(modelapp, newdata=dtest, type="response")

# Convertir les prédictions en classes (0 ou 1) en fonction d'un seuil de 0.5
predicted_class <- ifelse(predictions > 0.5, 1, 0)

roc_curve1 <- roc(dtest$target, prev)
plot(roc_curve1,col = "blue", lwd = 2)
auc_value <- auc(roc_curve1)
print(paste("AUC:", auc_value))
```
D'après la figure \ref{fig:Roc}, la est très proche du coin supérieur gauche du graphique, ce qui indique une excellente capacité de discrimination du modèle. le critère AUC est égal à 0.9947, ce qui est très proche de 1. On conlut que notre modèle est performant pour prédire les gènes sur-exprimés et sous-exprimés à 6h.

# Test d'indépendance
## Pour tous les traitements
Nous souhaitons déterminer si le caractère des gènes à 6h est influencé par le traitement. Pour ce faire, nous effectuerons un test non paramétrique d'indépendance de Khi-deux.
$H_{0}$: "le caractère est indépendant du traitement" contre $H_{1}$: "il existe une relation entre ces deux variables".
Pour mener ce test, nous construirons un tableau de contingence.

```{r Independance, echo=F}
moy_rep_6h = Moy_Rep[c(6,12,18)]
#knitr::kable(moy_rep_6h)

categorize <- function(x) {
  ifelse(x > 1, "Sur-exprimé", ifelse(x < -1, "Sous-exprimé", "Non exprimé"))
}

categories <- data.frame(
  T1 = apply(moy_rep_6h[, "T1_6h", drop = FALSE], 1, categorize),
  T2 = apply(moy_rep_6h[, "T2_6h", drop = FALSE], 1, categorize),
  T3 = apply(moy_rep_6h[, "T3_6h", drop = FALSE], 1, categorize)
)
#knitr::kable(categories)
# Tableau de contingence
table_contingence <- table(stack(categories))
knitr::kable(table_contingence)
```

En effectuant le test, on obtient les resultats suivants :

```{r test,echo=F}
# Test du Chi-2
chisq_test <- chisq.test(table_contingence)
print(chisq_test)
```

Compte tenu d'une p-valeur inférieure à 2.2e-16, nous rejetons l'hypothèse nulle selon laquelle le traitement n'influence pas l'expression génique à 6h. Cette conclusion est cohérente avec l'observation d'une interaction significative entre le traitement et le niveau d'expression initial. En effet, nous avons constaté que certains gènes sur-exprimés sous les traitements T2 et T3 ne le sont pas sous le traitement T1, et vice versa.

## Pour les traitements T2 et T3
On se limite aux 2 traitements T2 et T3 et on refait le même test du Khi-deux. On obtient la table de contingence ainsi que le test suivants:

```{r ind_T2_T3, echo=F}
# Filtrer pour T2 et T3
categories_T2_T3 <- categories[, c("T2", "T3")]

# Tableau de contingence pour T2 et T3
table_T2_T3 <- table(stack(categories_T2_T3))
knitr::kable(table_T2_T3)

# Test du Chi-2 pour T2 et T3
chisq_test_T2_T3 <- chisq.test(table_T2_T3)
print(chisq_test_T2_T3)
```

La p-valeur obtenue est de 0.7858, ce qui est bien supérieur au seuil de significativité de 0.05. Par conséquent, nous ne pouvons pas rejeter l'hypothèse nulle $H_{0}$.
L'hypothèse d'indépendance entre les traitements T2 et T3 et l'expression des gènes est donc confirmée. Cela signifie qu'il n'y a pas de différence significative dans l'expression des gènes à 6 heures en fonction du traitement (T2 ou T3).

En conclusion, les traitements T2 et T3 n'ont pas d'effet distinct sur l'expression des gènes dans le contexte étudié.

# Conclusion

Ce projet nous a permis d’explorer les données d’expression de 2144 gènes d’une plante modèle à travers différentes méthodes d’analyse statistique et de modélisation. Grâce aux techniques de réduction de dimension, de clustering et de modélisation prédictive, nous avons pu identifier des tendances et des relations significatives entre les traitements, le temps et l’expression des gènes.

L’analyse des clusters a révélé des structures cohérentes entre les différentes méthodes utilisées (\texttt{k-means}, classification hiérarchique et modèles de mélanges gaussiens), tout en mettant en évidence les spécificités de chaque approche.

L’étude des réplicats a montré des différences significatives dans l’expression des gènes, confirmées par les tests statistiques.

Les modèles de prédiction de l’expression des gènes à 6h ont mis en évidence l’importance du temps d’observation, le modèle basé sur l’expression à 3h offrant de meilleures performances que celui utilisant les données à 1h. Enfin, les tests d’indépendance ont permis d’évaluer l’impact des traitements sur l’expression génique et de mieux comprendre les interactions entre les différentes variables étudiées.

Ce travail met ainsi en lumière la complexité des dynamiques d’expression des gènes et la pertinence des outils statistiques pour leur analyse. Des perspectives d’amélioration pourraient inclure l’intégration de modèles non linéaires ou d’approches de machine learning plus avancées afin d’affiner les prédictions et d’explorer d’autres aspects de la régulation génique.

