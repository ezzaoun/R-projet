---
title: "Projet_commun"
author: "Castello Emeline, Seye Papa Samba et Aoun Ezzeddine"
output: 
  pdf_document:
    number_sections: true
header-includes:
  - \usepackage{float} 
date: "2024-11-04"
geometry: margin=1in
fontsize: 10pt
---

```{css,echo=F}
.badCode {
background-color: #cfdefc; 
}

.corrO { background-color: rgb(255,238,237); }
.corrS { background-color: pink; color: black; border: 1px solid red; }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE,
               cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               class.source="badCode")
```

```{r,warning=F,message=F,echo=F}
library(ggplot2)
library(gridExtra)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(corrplot)
library(forcats)
library(mclust)
library(cluster)
library(ppclust)
library(ggalluvial)
library(klaR)
library(gridExtra)
library(reshape2)
library(clusterSim)
library(pROC)
library(tidyverse)
library(leaps)
library(float)
```

## Partie 1 - Analyse descriptivre du jeu de données

## Statistique descriptive
Le jeu de données étudié possède 2144 génes et 36 variables qualitatives associées.
```{r, eval =F}
Data = read.table("DataProjet.txt", header =T)
knitr::kable(Data)
```

```{r, eval =T, echo = F}
Data = read.table("DataProjet.txt", header =T)
```
Nous allons ensuite afficher la distribution des mesures d'expression des génes pour les différents traitement, réplicat et temps.
```{r, eval = F}
options(max.print = 1000)
summary(Data)
```
On trace ensuite les corrélations entre les différentes variables représenté dans la figure 1 : "Corrélation".

```{r, eval = T, echo = F, fig.width=3, fig.height=3, fig.align = "center", fig.cap = "Corrélation"}
corrplot(cor(Data), method = "ellipse", tl.cex = 0.6)
```

Sur la Figure 1, on remarque la répétition d’un même forme entre le réplicat 1 et 2. On remarque également que dans chacune de ces formes la présence de carrés plus foncés pour chaque corrélation des traitements avec eux-même et pour la corrélation entre le traitement 2 et 3. Pour étudier plus en détaille ce graphique, on va extraire ces parties et expliquer chacune d'entre elles.
Dans un premier temps, on va extraire la corrélation pour chaque traitement avec eux même et la réprésenter (cf Figure 2)

```{r, eval = T, echo = F,fig.width=2, fig.height=2, fig.show='hold', fig.align = "center", results = "asis", fig.cap = "Corrélation pour chaque traitement avec eux même"}
#par(mar = c(5,2,2,2))
corrplot(cor(Data[,1:6]), method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data[,7:12]), method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data[,13:18]), method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
```

Sur la figure 2, on remarque que les heures ont une influence sur la corrélation. En effet, plus deux heures sont proches, plus la corrélation est élévée, ce qui montre l'évolution temporelle du traitement. Plus le traitement agit longtemps sur le gène, plus le traitement aura un effet important sur le gène.
Ensuite, on va extraire la corrélation entre chaque traitement (cf Figure 3).

```{r,eval = T, echo = F,fig.width=2, fig.height=2,fig.show='hold', fig.align = "center", fig.cap = "Corrélation entre chaque traitement"}
corrplot(cor(Data)[1:6,7:12], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[7:12, 13:18], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[13:18, 1:6], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
```

Sur la Figure 3, on observe que le traitement 2 et 3 sont plutot corrélé, supposant une efficacité similaire des deux traitements. Cependant, le traitement est peu corrélé avec le traitement 2 et 3, ce qui suppose encore une efficacité différente entre ces traitements.
On extrait également la corrélation en fonction des réplicats (cf Figure 4).

```{r, eval = T, echo = F,fig.width=2, fig.height = 2, fig.show='hold', fig.align = "center", fig.cap = "Corrélation en fonction des réplicats"}
corrplot(cor(Data)[c(19:24), c(1:6)], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[c(25:30), c(7:12)], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
corrplot(cor(Data)[c(31:36), c(13:18)], method = "ellipse", tl.cex = 0.4, cl.cex = 0.3)
```

Sur la Figure 4, on peut remarqué une corrélation importante entre les deux réplicat. Ainsi, une expérience produite deux fois renvoit des résultats qui sont corrélés entre eux. Cependant le traitement 2 et 3 pour les 2 réplicat sont plus corrélée à eux même que le traitement 1 ; ce qui suppose que le traitement 2 et 3 a une efficacité plus certaine que le traitement 1. Pour le traitement 2 et 3, on remarque que sur la diagonale (même traitement même heure mais réplicat différent), les corrélations sont proche de 1 mais varie légèrement en fonction des heures, cela met l’accent sur les vitesses de réactions variantes des traitements selon les gènes. 


```{r, eval = T, echo = F, fig.width=4, fig.height=2,fig.show='hold', fig.align = "center", fig.cap = "Boxplot des données"}
ggplot(melt(Data), aes(x = variable, y = value)) + geom_boxplot() + labs(title = "Boxplot des données", x = "Variable", y = "Valeur (échelle standardisée)") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  theme(plot.title = element_text(size = 9),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
        axis.text = element_text(size = 5))
```

```{r, eval = T, echo = F, fig.show='hold', fig.width=4,fig.height=2, fig.align = "center", fig.cap = "Distribution des Expression par Réplicat"}
# violin plot pour mieux visualiser 
data_long <- melt(Data, 
                  variable.name = "Condition", 
                  value.name = "Expression")

# Ajouter des colonnes pour séparer Réplicats, Traitements et Temps
data_long$Replicate <- ifelse(grepl("R1", data_long$Condition), "R1", "R2")
data_long$Treatment <- sub("_.*", "", data_long$Condition)
data_long$Time <- gsub(".*_(\\d+h)_.*", "\\1", data_long$Condition)

# Tracer le violin plot avec ggplot
ggplot(data_long, aes(x = Time, y = Expression, fill = Treatment)) +
  geom_violin(scale = "width", trim = TRUE) +
  facet_wrap(~ Replicate) +  # Facet par réplicat
  labs(title = "Distribution des Expressions par Réplicat, Temps et Traitement",
       x = "Temps",
       y = "Expression",
       fill = "Traitement") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
        axis.text = element_text(size = 5))
```

Sur la Figure 5, d’abord, on observe une distinction nette entre les réplicats R1 et R2, témoignant d’une périodicité dans les valeurs d'expression. Ce phénomène s'explique par le fait que les mêmes gènes sont soumis aux mêmes traitements et conditions pour chaque réplicat, bien que des variations aléatoires introduisent de légères différences.

Les boxplots révèlent trois groupes distincts correspondant aux traitements T1, T2, et T3.
- Pour le traitement T1, les médianes sont proches de 0, ce qui suggère une faible réaction des gènes ou l’absence d’un effet global mesurable. Les boîtes étroites et la faible variabilité confirment que la réponse des gènes reste homogène.
- Sous T2, les médianes s’éloignent nettement de 0, indiquant une réaction progressive des gènes au fil du temps.
- Étant une combinaison de T1 et T2, T3 présente des profils similaires à ceux de T2. Cela suggère que l’effet du traitement T2 domine dans l’effet global de T3, induisant une réponse notable des gènes. Cependant, il est possible que l’effet de T1 modère légèrement certaines réponses observées sous T3.

Ces observations s’appliquent de manière presque symétrique aux deux réplicats, illustrant leur homogénéité générale.

# Analyse des variables T\_t s\_H R\_r

## Analyse des composantes principales

Pour effectuer des analyses sur les variables, nous transposons notre jeu de données afin de considérer les variables initiales comme de nouveaux individus. Cette approche permet d'explorer les relations entre les variables et de visualiser leur structure dans un espace réduit. 

Une Analyse en Composantes Principales (ACP) sera réalisée sur ce jeu de données transposé. L’objectif est d’identifier les vecteurs qui maximisent l’inertie de la projection des données sur ces vecteurs. Ces derniers correspondent aux vecteurs propres associés aux plus grandes valeurs propres de la matrice de covariance des données, représentant ainsi les axes principaux de l’ACP.

Dans notre cas, il n'est pas nécessaire de réduire les données, car toutes les variables sont exprimées sur la même échelle.

```{r ACP_variables,echo=F,fig.width=5, fig.height=4,fig.align='center',fig.cap="\\label{fig:AcpVar}Projection des individus",fig.pos='H'}
# Transposition des données
transData <- t(Data)

# ACP sur les variables : transposée du tableau
respca <- PCA(transData, scale.unit = FALSE, graph = FALSE)

# Projection des individus dans l'espace des composantes principales
fviz_pca_ind(
  respca,
  axes = c(1, 2),
  geom = c("text", "point"),
  col.ind = rep(c(rep("T1", 6), rep("T2", 6), rep("T3", 6)), 2),
  repel = TRUE,
  labelsize = 2, # Réduction de la taille des étiquettes
  pointsize = 1  # Réduction de la taille des points
)
```

D'après la figure \ref{fig:AcpVar}, on observe :

- Les réplicats (R1 et R2) montrent une cohérence, car ils se regroupent dans l’espace factoriel pour un même traitement et une même heure. Cela confirme que les variations observées dans les données sont principalement dues aux effets des traitements et des temps, et non à des différences techniques entre les réplicats.

- Le traitement 1 se distingue des traitements 2 et 3 en formant un cluster isolé. L'axe 1 est tiré d'un coté par T1 à toutes les heures et dans les deux réplicats, et de l'autre coté par T2 et T3, surtout après 4h. On observe également des petits groupes isolés en haut, correspondants aux premières heures (1h, 2h, 3h) des traitements T2 et T3. Cela peut être interprété comme le passage d'un état où les gènes réagissent faiblement (à droite) à un état où ils commencent à répondre plus fortement au traitement. On peut interpéter Cette dimension comme le niveau d’expression des gènes.

- La dimension 2 semble être liée à la temporalité, avec une décroissance des heures du haut vers le bas.

## Clustering :

### Choix du nombre de classes 

Pour identifier le nombre de classes pour notre clustering, nous allons tracer l'inertie intraclasse, ainsi que la courbe Silhouette en fonction du nombre de classes possibles.

```{r nb_classes, echo=F,fig.width=5, fig.height=4,fig.align='center',fig.cap="\\label{fig:Silh}Sélection du nombre de classes optimal",fig.pos='H'}
set.seed(1234)
Kmax<-10
reskmeanscl<-matrix(0,nrow=nrow(transData),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(transData,centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}
df<-data.frame(K=2:10,Iintra=Iintra)
g1 = ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")

# Silouhette
Silhou<-NULL
for (k in 2:Kmax){
   aux<-silhouette(reskmeanscl[,k-1], dist(transData))
   Silhou<-c(Silhou,mean(aux[,3]))
}

df<-data.frame(K=2:Kmax,Silhouette=Silhou)
g2 = ggplot(df,aes(x=K,y=Silhouette))+
  geom_point()+
  geom_line()+theme(legend.position = "bottom")
grid.arrange(g1,g2,ncol=2)
```

D'après la figure \ref{fig:Silh}, on observe un coude marqué à 3 ou 4 classes pour l'inertie intraclasse. Dilhouette indique un nombre optimal de classes égal à 2. Cependant, nous optons pour 4 classes, car la projection des individus obtenue par l'ACP révèle une distinction claire entre 4 groupes, ce qui facilite une interprétation pertinente de chaque classe.

### Kmeans
```{r kmeans, echo=F,fig.width=5, fig.height=4,fig.align='center',fig.cap="\\label{fig:kmeans}Clustering à 4 classes avec Kmeans",fig.pos='H'}
reskmeans<-kmeans(transData,centers = 4)
fviz_cluster(reskmeans,transData,ellipse.type = "norm",repel=T,labelsize = 7)
```

Sur la figure \ref{fig:kmeans}, on observe :

- Une première classe regroupant les traitements T1 appliqués à toutes les heures pour les deux réplicats.

- Une deuxième classe contenant T2 et T3 à 1h pour les deux réplicats, située très proche de la classe T1. Cela suggère qu'à 1h, les gènes n'ont pas eu suffisamment de temps pour réagir aux traitements, expliquant l'absence d'effet visible et leur proximité avec la classe T1.

- Une troisième classe, composée de T2 et T3 à 2h et 3h pour les deux réplicats. À ce stade, les gènes commencent à réagir progressivement aux traitements. Cette classe se positionne à mi-chemin entre les classes avec une faible réaction et celle présentant une réaction significative.

- Une quatrième classe, contenant T2 et T3 à des heures supérieures à 4h, où les gènes réagissent aux traitements, montrant un effet significatif.

### Modèles de mélange 

Pour effectuer un clustering basé sur un modèle de mélanges, nous utilisons les coordonnées issues de l'ACP comme matrice de données pour classer les variables $T_ts_HR_r$. Ce choix est motivé par la taille de la matrice de variance-covariance du jeu de données initial, qui est $p*p=2144*2144$. Une matrice aussi grande serait coûteuse en temps de calcul et ralentirait considérablement la convergence vers le mélange optimal. En utilisant les coordonnées principales, nous réduisons la dimension tout en préservant l'essentiel de l'information.

Nous gardons les 5 premières composantes principales ce qui représente plus de 95% de l’inertie.
```{r nb_classes_mel, echo=F}
Dataacp<-respca$ind$coord[,1:5]
resICLall = mclustICL(Dataacp,G=2:20)
summary(resICLall)
```
A partir des resultats observés, on va garder 8 classes de volume variant $(V)$, de même étendu $(E)$ et d'orientation libre $(V)$ puisque l'ICL correspondant est le maximum.

```{r mel,echo=F,fig.width=3, fig.height=3,fig.align='center',fig.cap="\\label{fig:proba_boxplot}Les probabilités d'appartenance",fig.pos='H'}
modICL = Mclust(Dataacp, G = 8,modelNames = "VEV")
Aux = data.frame(label=paste("Cl",modICL$classification,sep=""),proba=apply(modICL$z,1,max))
ggplot(Aux,aes(x=label,y = proba)) + geom_boxplot()

classes_MEL = modICL$classification
classes_kmeans = reskmeans$cluster
table(classes_MEL,classes_kmeans)
```

Les points sont parfaitement classés, comme en témoigne la figure \ref{fig:proba_boxplot}. Toutes les probabilités d'appartenance sont à 1.

```{r lien,echo=F,fig.width=4, fig.height=3,fig.align='center',fig.cap="\\label{fig:lien_mel_kmeans}Lien entre la classification Kmeans et MEL",fig.pos='H'}
clust1<-paste("K-k",reskmeans$cluster,sep="")
clust2<-paste("MEL-k",modICL$classification,sep="")

Tab<-melt(table(clust1,clust2))
ggplot(Tab,aes(y=value,axis1=clust1,axis2=clust2))+
  geom_alluvium(aes(fill=clust1))+
  geom_stratum(width = 1/12)+   
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))+
  theme(legend.position = "none")
```


La figure \ref{fig:lien_mel_kmeans} montre que les classes générées par le modèle de mélanges sont des sous-classes de celles définies par K-means, sans aucun chevauchement.

```{r mel_ACP,echo=F,fig.width=4, fig.height=3,fig.align='center',fig.cap="\\label{fig:AcpVar_mel}Projection des individus classés par modèles de mélange",fig.pos='H'}
fviz_pca_ind(respca,col.ind=as.factor(modICL$classification),repel=T,labelsize = 2)
```

D'après la figure \ref{fig:AcpVar_mel}, on voit que le modèle de mélanges affine davantage la distinction entre les variables en segmentant les classes initiales en sous-classes plus spécifiques. Cette classification permet d'extraire davantage d'informations sur l'expression des gènes en fonction du traitement. Elle révèle que, dans une classe obtenue par k-means, il est possible d'identifier deux ou trois sous-classes présentant une expression similaire.

## Analyse des individus Gènes
### Partie ACP des individus


Nous nous intéressons ici aux individus. La figure \ref{fig:acp_ind} représente ces individus dans un espace réduit.


```{r, echo=FALSE,fig.height=3,fig.cap="\\label{fig:acp_ind}Représentation des individus sur les axes principaux de l'ACP"}
pca_res_ind <- PCA(Data, scale.unit = FALSE, graph = FALSE) 
fviz_pca_ind(pca_res_ind, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
```
Ce graphique met en évidence la formation de deux groupes distincts de gènes, répartis de part et d'autre du premier axe principal. Ce premier axe est celui qui sépare le mieux les gènes, indiquant que les 2 groupes contiennent des gènes présentant des profils d'expression très différents. Les gènes proches sur le graphique ont des profils d'expression similaires, tandis que ceux éloignés montrent des différences significatives. La coloration des points, basée sur le cos2, reflète la qualité de la projection des gènes : les couleurs chaudes indiquent une meilleure qualité de projection, ce qui signifie que ces gènes contribuent davantage à la variance expliquée dans cet espace réduit.

### Clustering K-means : 

Tout d'abord, nous utiliserons la méthode k-means pour étudier le clustering des individus. La figure \ref{fig:inertie_silhou} nous permettra de déterminer le nombre optimal de clusters en analysant l'évolution de l'inertie intra-classe et en utilisant le critère silhouette pour évaluer la qualité du clustering.


```{r, echo=FALSE,fig.height=3,fig.cap="\\label{fig:inertie_silhou}Évolution de l'inertie intra-classe et du critère silhouette"}
Kmax <- 15
reskmeanscl <- matrix(0, nrow = nrow(Data), ncol = Kmax - 1)
Iintra <- NULL

for (k in 1:Kmax) {
  resaux <- kmeans(Data, k, nstart = 1)
  reskmeanscl[, k - 1] <- resaux$cluster
  Iintra <- c(Iintra, resaux$tot.withinss)
}

df <- data.frame(K = 1:15, Iintra = Iintra)
g_intra = ggplot(df, aes(x = K, y = Iintra)) +
  geom_line() +
  geom_point() +
  xlab("Nombre de clusters") +
  ylab("Inertie intraclasse")

Silhou <- NULL
for (k in 2:Kmax) {
  aux <- silhouette(kmeans(Data, k)$cluster, daisy(Data))
  Silhou <- c(Silhou, mean(aux[, 3]))
}

df <- data.frame(K = 2:Kmax, Silhouette = Silhou)
g_silhou = ggplot(df, aes(x = K, y = Silhouette)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "bottom")

aux <- silhouette(kmeans(Data, centers = which.max(Silhou) + 1)$cluster, daisy(Data))
grid.arrange(g_intra, g_silhou, ncol=2)

```


La figure de gauche représente l'évolution de l'inertie intra-classe, qui diminue à mesure que le nombre de clusters augmente. Cependant, lorsque le nombre de clusters atteint un certain seuil, l'inertie devient stable et ne diminue plus de manière significative. Le point de coude dans le graphique nous aide à identifier le nombre optimal de clusters. Dans ce cas, le coude se forme lorsque le nombre de clusters est égal à 4, ce qui suggère que 4 clusters représentent le meilleur compromis entre la compacité des groupes et la simplicité du modèle.

La courbe de l'évolution du critère silhouette montre que le nombre optimal de clusters est égal à 2. Cependant, le critère silhouette est basé sur une moyenne, ce qui signifie qu'il peut être sensible à la présence d'outliers, et dans ce cas, il peut attribuer des clusters incorrects.

Nous pouvons maintenant représenter les individus dans l'espace réduit de l'ACP et les afficher selon leur cluster.


```{r, echo=FALSE, include=FALSE}
reskmeans<-kmeans(Data, 4)  
reskmeans$cluster
fviz_cluster(reskmeans, data=Data,ellipse=F,geom=c("point"))
```

```{r, fig.height=3,echo=FALSE,fig.cap="\\label{fig:k_means_ind}Clusters représentés sur les axes principaux"}
fviz_pca_ind(pca_res_ind, col.ind=as.factor(reskmeans$cluster), geom="point")
```

#### Clustering Hiérarchique (HAC)
La figure \ref{fig:dendo_ind} ci-dessous représente le clustering hiérarchique, permettant de créer un dendrogramme et de déterminer les clusters en coupant l'arbre à un niveau spécifique.

```{r, fig.cap="\\label{fig:deno_ind}Dendrogramme avec 2 clusters"}
hclust_res <- hclust(dist(Data))
plot(hclust_res, main = "Dendrogramme avec 2 clusters")
rect.hclust(hclust_res, k = 2, border = "red")
```

Le dendrogramme montre que les groupes de gènes qui se fusionnent tôt ont des profils d'expression trés similaires, tandis que ceux qui se rejoignent plus tard présentent des différences plus marquées. On observe que le nombre optimal de clusters est égal à 2. 

### Mélange gaussien

Nous nous intéressons ici à la méthode des mélanges gaussiens, basée sur l'hypothèse que les données suivent une distribution de probabilité composée de plusieurs distributions gaussiennes.

```{r, echo=FALSE, eval=FALSE}
mg_res <- mclustICL(Data, G=2:20, modelNames = c("EVE", "EEV", "EVV", "VEV", "VVV"))
```

Tout d'abord, nous allons déterminer le nombre optimal de clusters ainsi que le modèle le plus adapté pour notre jeu de données, en utilisant la méthode mclustICL avec une gamme de clusters de 2 à 20 et différents modèles de mélanges gaussiens (EVE, EEV, EVV, VEV, VVV).
```{r, fig.height=3, echo=FALSE}
table_data <- data.frame(
  "Best ICL values" = c("VEV,4", "VVV,4", "VEV,5"),
  "ICL" = c(-61554.37, -61722.510, -63474.420),
  "ICL diff" = c(0.00, -168.143, -1920.053)
)
table_data
```

```{r}
mg_res <- Mclust(data = Data, G = 4, modelNames = "VEV")
```


```{r, fig.height=3, echo=FALSE}
fviz_cluster(mg_res, data = Data, ellipse = TRUE, geom = "point", main = "Clustering avec Mélange Gaussien (ICL)")
```
Commentaire sur le chois du modele VEV et sur le clustering.


### Comparaison des différents algorithmes

#### Diagramme d'alluvion

Nous allons ici comparer les trois méthodes de clustering réalisées précédemment en utilisant un diagramme d'alluvion.

```{r, fig.height=3, echo=FALSE}
# Comparaison des résultats des 3 méthodes
clust1 <- paste("K-k", reskmeans$cluster, sep = "")
clust2 <- paste("CH-k", cutree(hclust_res, k = 2), sep = "")
clust3 <- paste("MG-k", mg_res$classification, sep = "")

# Tableau de comparaison
Tab <- melt(table(clust1, clust2, clust3))
ggplot(Tab, aes(y = value, axis1 = clust1, axis2 = clust2, axis3 = clust3)) +
  geom_alluvium(aes(fill = clust1)) +
  geom_stratum(width = 1 / 12) +
  geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  theme(legend.position = "none")

```


La première observation marquante est le flux important partant du cluster 1 des k-means vers le cluster de la classification hiérarchique, et se terminant dans les clusters 2, 3, et 4 du mélange gaussien. Cela suggère que les gènes sont classés de manière similaire dans les méthodes k-means et mélange gaussien, mais sont répartis dans 3 des 4 clusters du mélange gaussien.

### MCA sur les différentes méthodes

Une autre méthode de comparaison consiste à créer un tableau de contingence qui présente, pour chaque gène, les clusters obtenus selon les trois méthodes de clustering : k-means, classification hiérarchique, et mélanges gaussiens.

```{r, fig.height=3, echo=FALSE, eval=FALSE, include=FALSE}
library(kableExtra)
table_kmeans <- table(reskmeans$cluster)
table_hclust <- table(cutree(hclust_res, k = 2))
table_mg <- table(mg_res$classification)

table_kmeans_df <- as.data.frame(table_kmeans)
table_hclust_df <- as.data.frame(table_hclust)
table_mg_df <- as.data.frame(table_mg)

colnames(table_kmeans_df) <- c("Cluster", "Nombre d'éléments")
colnames(table_hclust_df) <- c("Cluster", "Nombre d'éléments")
colnames(table_mg_df) <- c("Cluster", "Nombre d'éléments")

kable(table_kmeans_df, col.names = c("Cluster", "Nombre d'éléments"), caption = "Tableau des tailles des clusters - K-means") 
kable(table_hclust_df, col.names = c("Cluster", "Nombre d'éléments"), caption = "Tableau des tailles des clusters - Classification hiérarchique")
kable(table_mg_df, col.names = c("Cluster", "Nombre d'éléments"), caption = "Tableau des tailles des clusters - Mélanges Gaussiens")

```


```{r, echo=FALSE,fig.height=3}
Kmeans = as.factor(reskmeans$cluster) 
Melange = as.factor(mg_res$classification)  
CAH = as.factor(cutree(hclust_res, k = 2)) 

df.clustering = data.frame(
  Kmeans = Kmeans,
  Melange = Melange,
  CAH = CAH
)

resMCA <- MCA(df.clustering, graph = FALSE) 
habillage_var <- ifelse(grepl("Kmeans", rownames(resMCA$var$coord)), "Kmeans",
                        ifelse(grepl("Melange", rownames(resMCA$var$coord)), "Melange", "CAH"))

g1 <- fviz_mca_var(resMCA,
             col.var = habillage_var,  
             repel = TRUE,  
             title = "MCA - Visualisation des Méthodes de Clustering",
             ggtheme = theme_minimal())  

g2 <- fviz_mca_var(resMCA, choice = "mca.cor",
             repel = TRUE,
             ggtheme = theme_minimal(),
             title = "MCA - Corrélations des Méthodes de Clustering")
grid.arrange(g1, g2, ncol=2, widths=c(2,1))
```

La première dimension est associée aux trois méthodes, tandis que la deuxième dimension semble être principalement influencée par k-means et le mélange gaussien. Les proximités observées entre les modalités sur le plan révèlent une forte association entre elles. Par exemple, on constate que le cluster 1 obtenu par k-means et le cluster 1 de la méthode hiérarchique sont très proches, ce qui suggère que plusieurs gènes classés dans le cluster 1 de k-means se retrouvent également dans le cluster 1 de la méthode hiérarchique. Cette observation confirme la comparaison réalisée à l'aide du diagramme d'alluvion.

## Etude des différences entre les deux réplicats

### Lois de probabilités
```{r}
replicat1 <- as.vector(unlist(Data[, c(1:18)]))
replicat2 <- as.vector(unlist(Data[, c(19:36)]))
```

```{r, echo=FALSE, fig.height=3}
df_replicats <- data.frame(
  value = c(replicat1, replicat2),
  replicat = factor(rep(c("Réplicat 1", "Réplicat 2"), c(length(replicat1), length(replicat2))))
)

ggplot(df_replicats, aes(x = value, fill = replicat, color = replicat)) +
  geom_density(alpha = 0.4, size = 1.2) +  
  scale_fill_manual(values = c("blue", "red")) + 
  scale_color_manual(values = c("blue", "red")) +
  labs(title = "Comparaison des réplicats", x = "Valeur", y = "Densité") +  
  theme_minimal() +  
  theme(legend.position = "top")  
```




```{r, echo=FALSE}
T1_R1 <- as.vector(unlist(Data[, c(1,6)]))
T1_R2 <- as.vector(unlist(Data[, c(19,24)]))
T2_R1 <- as.vector(unlist(Data[, c(7,12)]))
T2_R2 <- as.vector(unlist(Data[, c(25,30)]))
T3_R1 <- as.vector(unlist(Data[, c(13,18)]))
T3_R2 <- as.vector(unlist(Data[, c(31,36)]))

ks.test(replicat1, replicat2)
ks.test(T1_R1, T1_R2)
ks.test(T2_R1, T2_R2)
ks.test(T3_R1, T3_R2)
```

### Effet combiné du temps et du traitement 

Nous cherchons à étudier l’effet combiné du temps et du traitement sur la différence des deux réplicats. Pour ce faire, nous définissons une nouvelle variable \( Y_{tsg} \) :
$$
Y_{tsg} = Y_{tsgR1} - Y_{tsgR2}, t\in\{1,\ldots,3\} ,\ s\in\{1,\ldots,6\} ,\ g\in\{1,\ldots,2144\}.
$$
L'objectif est de modéliser cette variable en fonction de deux facteurs principaux : le temps (variable quantitative) et le traitement (variable qualitative).

Pour ce faire, nous utilisons un \textbf{modèle ANCOVA avec interaction}, qui permet de modéliser la relation entre la variable dépendante \( Y_{tsg} \) et les deux facteurs (temps et traitement), ainsi que leur interaction.
$$
Y_{tsg} = \beta_0 + \beta_1 \cdot Temps + \beta_2 \cdot Traitement + \beta_3 \cdot (Temps \times Traitement) + \epsilon_{tsg} 
$$
- $Temps$: Variable quantitative représentant le temps.

- $Traitement$: Variable catégorielle (0 ou 1) indiquant si le gène a été soumis au traitement.

```{r modele_ANCOVA,echo=F}
# Etape 1 : On effectue la différence des réplicats
p = ncol(Data)

Data_Diff_R = Data[,1:(p/2)] - Data[,((p/2) + 1):p]
colnames(Data_Diff_R) <- sub("_[^_]*$", "", colnames(Data[,1:(p/2)]))

#Etape 2 : Création de Yij de telle sorte que Y_ij = Y_tsg
Y = as.vector(as.matrix(Data_Diff_R))

#Etape 3 : Création des noms de lignes du vecteur Y
noms_Y <- outer(colnames(Data_Diff_R), rownames(Data_Diff_R), paste, sep="_")
noms_Y <- as.vector(t(noms_Y))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)
temps <- as.numeric(sapply(strsplit(noms_Y, "[_h]"), function(x) x[2]))

# Etape 5 : Création du tableau pour le modèle linéaire
matrix = as.data.frame(cbind(Y, traitement, temps))
matrix$temps <- as.numeric(matrix$temps)
matrix$Y <- as.numeric(matrix$Y)

rownames(matrix) <- noms_Y
```


```{r Model, echo=F,include=F}
ML <- lm(Y~traitement*temps, data = matrix)
summary(ML)
```

On établit le modèle sans intéraction

```{r Model_sans_inter, echo=F,include=F}
ML_no_inter = lm(Y~traitement+temps,data=matrix)
summary(ML_no_inter)
```

```{r courbe_inter,echo=F,fig.width=5, fig.height=4,fig.align='center',fig.cap="\\label{fig:interaction}Interaction plot"}
# Modèle sans interaction
M_non_interaction <- lm(Y ~ traitement + temps, data = matrix)

# Modèle avec interaction
M_interaction <- lm(Y ~ traitement * temps, data = matrix)

# Création des nouvelles données pour prédiction
new_data <- expand.grid(
  traitement = unique(matrix$traitement),
  temps = seq(min(matrix$temps), max(matrix$temps), length.out = 100)
)

# Prédictions
new_data$Y_non_interaction <- predict(M_non_interaction, newdata = new_data)
new_data$Y_interaction <- predict(M_interaction, newdata = new_data)

# Graphique pour le modèle sans interaction
plot_non_interaction <- ggplot(new_data, aes(x = temps, y = Y_non_interaction, color = traitement)) +
  geom_line(size = 1) +
  labs(title = "Modèle sans interaction",
       x = "Temps",
       y = "Valeurs prédites de Y",
       color = "Traitement") +
  theme_minimal()

# Graphique pour le modèle avec interaction
plot_interaction <- ggplot(new_data, aes(x = temps, y = Y_interaction, color = traitement)) +
  geom_line(size = 1) +
  labs(title = "Modèle avec interaction",
       x = "Temps",
       y = "Valeurs prédites de Y",
       color = "Traitement") +
  theme_minimal()

# Affichage côte à côte
grid.arrange(plot_non_interaction, plot_interaction, ncol = 2)
```

Dans le modèle sans interaction, les courbes sont parallèles, reflétant l'absence d'interdépendance entre le traitement et le temps. En revanche, dans le modèle avec interaction, les courbes montrent des variations de pente ou des croisements, indiquant une présence probable d'interaction entre ces deux variables. À partir de ces deux représentations, un test de sous-modèle est effectué pour déterminer si l'interaction doit être conservée dans le modèle final.

```{r Compare_modeles, echo=F}
anova(ML_no_inter,ML)
```
La p-valeur obtenue est de $1.426e-15<0.05$. Cela conduit à rejeter largement l'hypothèse nulle et à privilégier le modèle avec interaction.

## Pédiction de l’expression des gènes à 6h

### A partir de l'expressions des gènes à 1h

Nous avons calculé la moyenne des réplicats pour chaque gène et chaque temps, notée $Y_{tsgMoy}$. Un modèle ANCOVA avec interaction a été ajusté pour prédire l'expression finale (à t=6h) en fonction de l'expression initiale (à t=1h) et du traitement :
$$
Y_{t6hgMoy} = \beta_0 + \beta_1 \cdot Y_{t1hgMoy} + \beta_2 \cdot Traitement + \beta_3 \cdot (Y_{t1hgMoy} \times Traitement) + \epsilon_{tsg}
$$
où :

- $Y_{t6hgMoy}$ est l'expression moyenne du gène g au temps t=6h.

- $Y_{t1hgMoy}$ est l'expression moyenne du gène g au temps t=1h (expression initiale).

- Traitement : est une variable indicatrice (0 ou 1) indiquant si le gène a été soumis au traitement.

- Les coefficients $\beta$ représentent les effets respectifs de l'ordonnée à l'origine, de l'expression initiale, du traitement et de l'interaction entre l'expression initiale et le traitement.

- $\epsilon_{tsg}$ est un terme d'erreur aléatoire.
```{r Ancova_6h_1h,echo=F}
# extraire les Y à 1h et créer une matrice
p = ncol(Data)
Data_moy_R = (Data[,1:(p/2)] + Data[,((p/2) + 1):p])/2
Data_moy_R_1h = Data_moy_R[,c(1,7,13)]
Data_moy_R_6h = Data_moy_R[,c(6,12,18)]

colnames(Data_moy_R_1h) <- sub("_[^_]*$", "", colnames(Data_moy_R_1h))


colnames(Data_moy_R_6h) <- sub("_[^_]*$", "", colnames(Data_moy_R_6h))


Y_moy_1h = as.vector(as.matrix(Data_moy_R_1h))
Y_moy_6h = as.vector(as.matrix(Data_moy_R_6h))

#Etape 3 : Création des noms de lignes du vecteur Y
noms_Y <- outer(colnames(Data_moy_R_1h), rownames(Data_moy_R_1h), paste, sep="_")
noms_Y <- as.vector(t(noms_Y))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)

# Etape 5 : Création du tableau pour le modèle linéaire
matrixMoy = as.data.frame(cbind(Y_moy_6h, Y_moy_1h, traitement))
matrixMoy$Y_moy_1h <- as.numeric(matrixMoy$Y_moy_1h)
matrixMoy$Y_moy_6h <- as.numeric(matrixMoy$Y_moy_6h)
```

```{r Model_6h_1h,echo=F,include=F}
M_1h_to_6h <- lm(Y_moy_6h~Y_moy_1h*traitement, data = matrixMoy)
summary(M_1h_to_6h)
```

```{r observed_fitted_plot, echo=F,fig.width=7, fig.height=4,fig.align='center',fig.cap="\\label{fig:obsVSpred1}Repésentation de la qualité du modèle"}
# Prédictions à partir du modèle
matrixMoy$Predicted <- predict(M_1h_to_6h, newdata = matrixMoy)

# Tracé des valeurs observées (Y_moy_6h) par rapport aux valeurs prédites
g1 = ggplot(matrixMoy, aes(x = Predicted, y = Y_moy_6h)) +
  geom_point(aes(color = traitement), alpha = 0.6) +  # Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
fitted_vals <- fitted(M_1h_to_6h)
residuals <- resid(M_1h_to_6h)
g2 = ggplot(data = data.frame(Fitted = fitted_vals, Residuals = residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "blue", alpha = 0.6) + # Points des résidus
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + # Ligne à y = 0
  theme_minimal() + # Thème esthétique minimal
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
grid.arrange(g1,g2,ncol=2)
```

On observe que les valeurs prédites sont principalement proches de 0, tandis que les valeurs observées, en particulier pour les traitements T2 et T3, diffèrent significativement de 0. Cela suggère que l'expression des gènes à 1h ne constitue pas un bon indicateur pour prédire celle à 6h.
En effet, 1 heure représente un stade relativement précoce, et les gènes n'ont probablement pas eu suffisamment de temps pour réagir aux traitements. Par conséquent, il est difficile de faire des prédictions fiables sur l'expression génique à 6 heures en se basant sur des données obtenues à 1 heure.

Le graphique des résidus vs valeurs ajustées indique que notre modèle actuel présente des problèmes. La dispersion non uniforme des résidus suggère une hétéroscédasticité: la variabilité des erreurs n'est pas constante. De plus, la légère tendance non-linéaire des résidus indique que la relation entre les variables pourrait être plus complexe que ce que notre modèle linéaire simple ne capture.
En d'autres termes, le modèle que nous utilisons actuellement ne semble pas être le plus adapté à nos données. Des ajustements sont nécessaires pour obtenir des résultats plus fiables.

**Conclusion**:
Le modèle ajusté montre une qualité d'ajustement modérée, avec un R² de 27.06%. Les termes d’interaction entre $Y_{1h}$ et le traitement sont hautement significatifs (p<2e−16), ce qui montre que l’effet de $Y_{1h}$ sur $Y_{6h}$ varie selon le traitement. 
En se basant sur les graphiques obtenus, le modèle que nous utilisons actuellement ne semble pas être le plus adapté à nos données. Des ajustements sont nécessaires pour obtenir des résultats plus fiables.

### A partir de l'expressions des gènes à 3h

Nous souhaitons prédire $Y_{6h}$ en utilisant $Y_{3h}$ comme variable explicative principale. Pour ce faire, nous allons reprendre le modèle précédent et l'adapter en remplaçant toutes les variables correspondant aux données au temps $1h$ par leurs équivalents au temps $3h$. 
```{r Ancova_6h_3h,echo=F}
p = ncol(Data)

Data_moy_R_3h = Data_moy_R[,c(3,9,15)]

colnames(Data_moy_R_3h) <- sub("_[^_]*$", "", colnames(Data_moy_R_3h))

Y_moy_3h = as.vector(as.matrix(Data_moy_R_3h))

#Etape 4 : Création du vecteur traitement et temps
traitement <- sub("_.*", "", noms_Y)

# Etape 5 : Création du tableau pour le modèle linéaire
matrixMoy2 = as.data.frame(cbind(Y_moy_6h, Y_moy_3h, traitement))
matrixMoy2$Y_moy_6h <- as.numeric(matrixMoy2$Y_moy_6h)
matrixMoy2$Y_moy_3h <- as.numeric(matrixMoy2$Y_moy_3h)

```


```{r Model_6h_3h, echo=F,include=F}
M_3h_to_6h <- lm(Y_moy_6h~Y_moy_3h*traitement, data = matrixMoy2)
summary(M_3h_to_6h)
```
- Residual Standard Error (RSE) : 1.168
- R² ajusté : 0.770
- La variance expliquée est beaucoup plus élevée, indiquant que les prédictions du modèle pour les données à 3h sont nettement meilleures.

Le modèle basé sur les données de 3h semble être plus performant que celui de 1h, avec un R² ajusté presque trois fois supérieur et un RSE significativement plus faible. Cela signifie que les valeurs à 3h prédisent mieux les valeurs à 6h.

On trace la courbe des valeurs observées par rapport aux valeurs prédites, ainsi que les résidus par rapport aux valeurs prédites.

```{r observed_fitted,echo=F,fig.width=7,fig.height=4,fig.align='center',fig.cap="\\label{fig:obsVSpred2}Repésentation de la qualité du modèle"}
# Prédictions à partir du modèle
matrixMoy2$Predicted <- predict(M_3h_to_6h, newdata = matrixMoy2)

# Tracé des valeurs observées (Y_moy_6h) par rapport aux valeurs prédites
library(ggplot2)
g1 = ggplot(matrixMoy2, aes(x = Predicted, y = Y_moy_6h)) +
  geom_point(aes(color = traitement), alpha = 0.6) +  # Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
new_fitted_vals <- fitted(M_3h_to_6h)
new_residuals <- resid(M_3h_to_6h)
g2 = ggplot(data = data.frame(Fitted = new_fitted_vals, Residuals = new_residuals), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "blue", alpha = 0.6) + # Points des résidus
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") + # Ligne à y = 0
  theme_minimal() + # Thème esthétique minimal
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
grid.arrange(g1,g2,ncol=2)
```

On observe que les valeurs prédites s'alignent bien avec les valeurs observées, et que les résidus sont plus uniformément dispersés autour de 0. Cela indique une amélioration notable de la qualité des prédictions par rapport au modèle précédent.



## Etude de l’expression des gènes pour le traitement T3 à 6h :

```{r MLG, echo=F,include=F}
# Matrice moyenne des replicats
p = ncol(Data)
Moy_Rep = (Data[,1:(p/2)] + Data[,((p/2) + 1):p])/2
colnames(Moy_Rep) <- sub("_[^_]*$", "", colnames(Data[,1:(p/2)]))

modele_T3_all <- lm(T3_6h ~ T1_1h + T1_2h + T1_3h + T1_4h + T1_5h + T1_6h +
                      T2_1h + T2_2h + T2_3h + T2_4h + T2_5h + T2_6h, 
                    data = Moy_Rep)
summary(modele_T3_all)
```


```{r Selection, echo=F}
choix = regsubsets(T3_6h~T1_1h + T1_2h + T1_3h + T1_4h + T1_5h + T1_6h +
                      T2_1h + T2_2h + T2_3h + T2_4h + T2_5h + T2_6h,data=Moy_Rep,nbest=1,nvmax=11,method="backward")
plot(choix,scale="Cp")

new_modele_T3_all <- lm(T3_6h ~ T1_1h + T1_2h + T1_3h + T1_4h + T1_6h +
                      T2_2h + T2_3h + T2_4h + T2_5h + T2_6h, 
                    data = Moy_Rep)
anova(new_modele_T3_all,modele_T3_all)
```


```{r coeff,fig.width=5,fig.height=3,echo=F}
# Extraire les coefficients significatifs
coef_model <- summary(modele_T3_all)$coefficients
coef_df <- data.frame(
  Variable = rownames(coef_model),
  Coefficient = coef_model[, "Estimate"],
  P_value = coef_model[, "Pr(>|t|)"]
)

# Filtrer les variables significatives (p-value < 0.05)
coef_df <- coef_df[coef_df$P_value < 0.05, ]

# Créer un barplot des coefficients
ggplot(coef_df, aes(x = reorder(Variable, Coefficient), y = Coefficient)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Coefficients significatifs du modèle", x = "Variable", y = "Coefficient")
```


```{r predict,fig.width=7,fig.height=4,echo=F}
tmp = Moy_Rep
tmp$Predicted <- predict(new_modele_T3_all, newdata = tmp)
ggplot(tmp, aes(x = Predicted, y = T3_6h)) +
  geom_point() +# Points colorés par traitement
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Ligne Y = X
  labs(
    title = "Valeurs Observées vs Prédites",
    x = "Valeurs prédites",
    y = "Valeurs observées"
  ) +
  theme_minimal()
```


Consigne : Peut-on prédire les gènes sur-exprimés (codés 1) et les gènes sous-exprimés (codés 0) à 6h pour le
traitement T3 à partir des observations pour les traitements T1 et T2 et les heures 1 à 3 pour ces
mêmes gènes ?


```{r, echo=F,include=F}
# Filtrer les données en excluant les valeurs intermédiaires (-1 <= T3_6h <= 1)
x = Moy_Rep[Moy_Rep$T3_6h < 1 & Moy_Rep$T3_6h > -1, ]
# 8 genes non classés
filtered_data <- Moy_Rep[Moy_Rep$T3_6h < -1 | Moy_Rep$T3_6h > 1, ]
# Définir la colonne target selon les critères donnés
filtered_data$target <- as.factor(ifelse(filtered_data$T3_6h > 1, 1, 0))
filtered_data <- filtered_data[, c("T1_1h", "T1_2h", "T1_3h", "T2_1h", "T2_2h", "T2_3h","target")]

table(filtered_data$target)

model <- glm(filtered_data$target ~. , data = filtered_data, family = "binomial")

summary(model)

step.backward = step(model, direction="backward",k=log(nrow(filtered_data)))

bestmodel = glm(filtered_data$target ~T2_2h + T1_2h +T1_3h + T2_3h , data = filtered_data, family = "binomial")
anova(bestmodel,model)
```

```{r, echo=F}
l<-1000
# pour ne pas prendre des données rangées pour le test (qui viennent apres ceux d'apprentissage)
perm<-sample(nrow(filtered_data))
# Echantillon d'apprentissage
dapp<-filtered_data[perm[1:l],]
# Echantillon test
dtest<-filtered_data[-perm[1:l],]
# Estimation du modèle sur l'échantillon d'apprentissage
modelapp<-glm(target ~. , family = "binomial",data=dapp)
# Prédictions sur l'échantillon test
prev<-predict(modelapp,newdata=dtest,type="response")

roc_curve1 <- roc(dtest$target, prev)
plot(roc_curve1, main = "Courbe ROC", col = "blue", lwd = 2)

# Prédire sur les données de test ou validation
predictions <- predict(model, newdata = filtered_data, type = "response")

# Convertir les prédictions en classes (0 ou 1) en fonction d'un seuil de 0.5
predicted_class <- ifelse(predictions > 0.5, 1, 0)

# Matrice de confusion
table(predicted_class, filtered_data$target)
adjustedRandIndex(predicted_class, filtered_data$target)

roc_curve <- roc(filtered_data$target, predictions)
plot(roc_curve, main = "Courbe ROC", col = "blue", lwd = 2)
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))

```



```{r, echo=F}
model_inter <- glm(filtered_data$target ~(.)^2 , data = filtered_data, family = "binomial")
summary(model_inter)

modelbestinter = step(model_inter,trace=F)
modelbestinter
```


Consigne : Le caractère sur exprimé/sous exprimé/non exprimé des gènes à 6h dépend-il du traitement ? Même
question si on se limite aux traitements T2 et T3.

pour chaque traitement, on prend les reponses des genes à 6h et on cree un data frame 
```{r, echo=F}
moy_rep_6h = Moy_Rep[c(6,12,18)]
#knitr::kable(moy_rep_6h)

categorize <- function(x) {
  ifelse(x > 1, "Sur-exprimé", ifelse(x < -1, "Sous-exprimé", "Non exprimé"))
}

categories <- data.frame(
  T1 = apply(moy_rep_6h[, "T1_6h", drop = FALSE], 1, categorize),
  T2 = apply(moy_rep_6h[, "T2_6h", drop = FALSE], 1, categorize),
  T3 = apply(moy_rep_6h[, "T3_6h", drop = FALSE], 1, categorize)
)
#knitr::kable(categories)
# Tableau de contingence
table_contingence <- table(stack(categories))
print(table_contingence)

# Test du Chi-2
chisq_test <- chisq.test(table_contingence)
print(chisq_test)
```


```{r, echo=F}
# Filtrer pour T2 et T3
categories_T2_T3 <- categories[, c("T2", "T3")]

# Tableau de contingence pour T2 et T3
table_T2_T3 <- table(stack(categories_T2_T3))

# Test du Chi-2 pour T2 et T3
chisq_test_T2_T3 <- chisq.test(table_T2_T3)
print(chisq_test_T2_T3)

```


```{r, echo=F}
library(ggplot2)

# Préparer les données pour ggplot
plot_data <- as.data.frame(table_contingence)
colnames(plot_data) <- c("Category", "Treatment", "Count")

# Visualisation
ggplot(plot_data, aes(x = Treatment, y = Count, fill = Category)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Distribution des gènes par catégorie et traitement",
       x = "Traitement",
       y = "Nombre de gènes") +
  theme_minimal()
```
